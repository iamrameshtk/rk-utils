#!/usr/bin/env python3
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime, timedelta
import pytz
import re

class GitHubMetricsDashboard:
    """
    Streamlined Streamlit dashboard for visualizing GitHub repository metrics reports.
    Displays simplified summary information from Excel reports generated by the GitHub Metrics Reporter.
    """
    
    def __init__(self):
        """Initialize dashboard with configuration and setup."""
        self.utc = pytz.UTC
        self.reports_root = 'reports_*'  # Pattern to find report directories
        self.custom_output_dirs = ['output', 'outputs', 'report', 'reports']  # Common custom output directories
        self.latest_report_dir = None
        
        # Set page configuration
        st.set_page_config(
            page_title="GitHub Metrics Dashboard",
            page_icon="ðŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # Set title
        st.title("GitHub Repository Metrics Dashboard")
    
    def find_latest_report(self):
        """Find the most recent report directory based on timestamp in directory name or file modification time."""
        try:
            # Start with default report directories (reports_*)
            report_dirs = glob.glob(self.reports_root)
            
            # Add custom output directories if they exist
            for custom_dir in self.custom_output_dirs:
                if os.path.isdir(custom_dir):
                    report_dirs.append(custom_dir)
            
            if not report_dirs:
                st.error("No report directories found. Please generate reports first.")
                return None
                
            # Track potential report directories with their timestamps
            timestamps = []
            
            for dir_name in report_dirs:
                # Check if this is a timestamped reports directory
                match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
                if match:
                    timestamp_str = match.group(1)
                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                        timestamps.append((timestamp, dir_name))
                        continue
                    except ValueError:
                        pass  # Not a valid timestamp format, will check for Excel files below
                
                # Check if Excel report files exist in this directory
                pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(dir_name, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    # Use the most recent modification time as the timestamp
                    pr_mtime = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                    contrib_mtime = datetime.fromtimestamp(os.path.getmtime(contributor_report_path))
                    timestamp = max(pr_mtime, contrib_mtime)
                    timestamps.append((timestamp, dir_name))
            
            if not timestamps:
                st.error("No valid report directories or files found.")
                return None
                
            # Get the most recent directory
            latest = max(timestamps, key=lambda x: x[0])
            return latest[1]
            
        except Exception as e:
            st.error(f"Error finding report directory: {str(e)}")
            return None
    
    def scan_for_report_directories(self):
        """Scan for all potential directories containing reports."""
        # Start with default report directories (reports_*)
        report_dirs = glob.glob(self.reports_root)
        
        # Add custom output directories if they exist and contain report files
        for custom_dir in self.custom_output_dirs:
            if os.path.isdir(custom_dir):
                pr_report_path = os.path.join(custom_dir, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(custom_dir, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    report_dirs.append(custom_dir)
        
        # Also check current directory for report files
        pr_report_path = 'pr_activity_report.xlsx'
        contributor_report_path = 'contributor_report.xlsx'
        if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
            report_dirs.append('.')
            
        return report_dirs
    
    def create_report_options(self, report_dirs):
        """Create formatted options for report selection dropdown."""
        report_options = []
        
        for dir_name in report_dirs:
            # First try to extract timestamp from directory name
            match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
            if match:
                timestamp_str = match.group(1)
                try:
                    timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                    report_options.append((readable_name, dir_name, timestamp))
                    continue
                except ValueError:
                    pass  # Invalid timestamp format, fall back to file modification time
            
            # Use file modification time for other directories
            pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
            if os.path.exists(pr_report_path):
                timestamp = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                if dir_name == '.':
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} (Current Directory)"
                else:
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                report_options.append((readable_name, dir_name, timestamp))
        
        # Sort by timestamp (newest first)
        report_options.sort(key=lambda x: x[2], reverse=True)
        return [(name, dir_name) for name, dir_name, _ in report_options]
    
    def load_report_data(self, custom_dir=None):
        """Load data from Excel reports in the specified or latest directory."""
        try:
            # Find the latest report directory if none specified
            report_dir = custom_dir if custom_dir else self.find_latest_report()
            if not report_dir:
                return None, None
                
            self.latest_report_dir = report_dir
            
            # Construct file paths
            pr_report_path = os.path.join(report_dir, 'pr_activity_report.xlsx')
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if files exist
            if not os.path.exists(pr_report_path) or not os.path.exists(contributor_report_path):
                st.error(f"Required report files not found in {report_dir}")
                return None, None
                
            # Load PR Activity data
            pr_summary_df = pd.read_excel(pr_report_path, sheet_name='Repository Summary')
            pr_activity_df = pd.read_excel(pr_report_path, sheet_name='PR Activity')
            
            # Load Contributor data
            contributor_summary_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Summary')
            contributor_detail_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Metrics')
            
            # Return data package
            return {
                'pr_summary': pr_summary_df,
                'pr_activity': pr_activity_df,
                'contributor_summary': contributor_summary_df,
                'contributor_detail': contributor_detail_df
            }, report_dir
            
        except Exception as e:
            st.error(f"Error loading report data: {str(e)}")
            return None, None
    
    def add_weekly_range_filter(self, min_date, max_date, default_weeks=4, section_key="default"):
        """Add a weekly range filter to filter data by date."""
        st.subheader("Date Range Filter")
        
        # Calculate default date range (last 4 weeks by default)
        if isinstance(min_date, str):
            min_date = datetime.strptime(min_date, '%Y-%m-%d')
        if isinstance(max_date, str):
            max_date = datetime.strptime(max_date, '%Y-%m-%d')
        
        default_end = max_date
        default_start = max_date - timedelta(weeks=default_weeks)
        # Ensure default_start is not earlier than min_date
        default_start = max(default_start, min_date)
        
        # Create two columns for start and end date inputs
        col1, col2 = st.columns(2)
        
        with col1:
            start_date = st.date_input(
                "Start Date",
                value=default_start,
                min_value=min_date,
                max_value=max_date,
                key=f"start_date_{section_key}"
            )
        
        with col2:
            end_date = st.date_input(
                "End Date",
                value=default_end,
                min_value=min_date,
                max_value=max_date,
                key=f"end_date_{section_key}"
            )
        
        # Add quick selection buttons for common time periods
        st.write("Quick select:")
        col1, col2, col3, col4 = st.columns(4)
        
        # Store the selected period in session state
        if "date_range" not in st.session_state:
            st.session_state.date_range = {}
        
        with col1:
            if st.button("Last Week", key=f"last_week_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=1),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col2:
            if st.button("Last Month", key=f"last_month_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=4),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col3:
            if st.button("Last Quarter", key=f"last_quarter_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=13),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col4:
            if st.button("All Time", key=f"all_time_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": min_date,
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        # Check if we have stored dates from buttons
        if section_key in st.session_state.date_range:
            return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        # Ensure end_date is not before start_date
        if end_date < start_date:
            st.error("End date must be after start date")
            end_date = start_date
        
        st.markdown("---")
        
        return start_date, end_date
    
    def create_overall_summary(self, data):
        """Create overall summary metrics from the report data - simplified version."""
        try:
            st.header("Overall Repository Health Summary")
            
            pr_summary = data['pr_summary']
            
            # Display report timestamp
            if self.latest_report_dir:
                match = re.search(r'reports_(\d{8}_\d{6})', self.latest_report_dir)
                if match:
                    timestamp_str = match.group(1)
                    report_date = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    st.info(f"Report generated on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
                else:
                    # For non-timestamped directories, use the modification time of PR report
                    pr_report_path = os.path.join(self.latest_report_dir, 'pr_activity_report.xlsx')
                    if os.path.exists(pr_report_path):
                        report_date = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                        st.info(f"Report last modified on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Create metrics columns
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.metric(
                    label="Total Repositories", 
                    value=len(pr_summary)
                )
                
                st.metric(
                    label="Total Contributors", 
                    value=len(data['contributor_summary'])
                )
            
            with col2:
                total_prs = pr_summary['Total PRs'].sum()
                merged_prs = pr_summary['Merged PRs'].sum()
                
                st.metric(
                    label="Total PRs", 
                    value=total_prs
                )
                
                merge_percentage = round((merged_prs / total_prs) * 100, 1) if total_prs > 0 else 0
                st.metric(
                    label="Merged PRs", 
                    value=merged_prs,
                    delta=f"{merge_percentage}%"
                )
            
            with col3:
                healthy_prs = pr_summary['Healthy PRs'].sum()
                unhealthy_prs = pr_summary['Unhealthy PRs'].sum()
                
                st.metric(
                    label="Healthy PRs", 
                    value=healthy_prs
                )
                
                st.metric(
                    label="Needs Attention PRs", 
                    value=unhealthy_prs,
                    delta="-" + str(unhealthy_prs),  # Convert to string
                    delta_color="inverse"
                )
            
            with col4:
                # Calculate total passed and failed checks
                total_passed = 0
                total_failed = 0

                # First try to get the values from pr_summary (repository level aggregates)
                if 'Passed Checks' in pr_summary.columns:
                    total_passed = pr_summary['Passed Checks'].sum()
                    
                if 'Failed Checks' in pr_summary.columns:
                    total_failed = pr_summary['Failed Checks'].sum()

                # If the totals are still 0, try to calculate from pr_activity (individual PR level)
                if total_passed == 0 and total_failed == 0 and 'pr_activity' in data:
                    pr_activity = data['pr_activity']
                    if 'Passed Checks' in pr_activity.columns:
                        total_passed = pr_activity['Passed Checks'].sum()
                    if 'Failed Checks' in pr_activity.columns:
                        total_failed = pr_activity['Failed Checks'].sum()
                st.metric(
                    label="Passed Checks", 
                    value=total_passed
                )

                st.metric(
                    label="Failed Checks", 
                    value=total_failed,
                    delta="-" + str(total_failed) if total_failed > 0 else "0",
                    delta_color="inverse" if total_failed > 0 else "normal"
                )
            
            with col5:
                # Display branch metrics if available
                total_branches = pr_summary['Total Branches'].sum() if 'Total Branches' in pr_summary.columns else 0
                active_branches = pr_summary['Active Branches'].sum() if 'Active Branches' in pr_summary.columns else 0
                stale_branches = pr_summary['Stale Branches'].sum() if 'Stale Branches' in pr_summary.columns else 0
                
                st.metric(
                    label="Total Branches", 
                    value=total_branches
                )
                
                st.metric(
                    label="Stale Branches", 
                    value=stale_branches,
                    delta="-" + str(stale_branches) if stale_branches > 0 else "0",
                    delta_color="inverse" if stale_branches > 0 else "normal"
                )
            
            # Repository health table
            st.subheader("Repository Health Overview")
            
            # Calculate health percentage for sorting
            health_overview = pr_summary[['Repository', 'Total PRs', 'Healthy PRs', 'Unhealthy PRs']].copy()
            # Rename for display
            health_overview = health_overview.rename(columns={'Unhealthy PRs': 'Needs Attention PRs'})
            
            # Add branch columns if available
            if all(col in pr_summary.columns for col in ['Total Branches', 'Active Branches', 'Stale Branches']):
                health_overview['Total Branches'] = pr_summary['Total Branches']
                health_overview['Active Branches'] = pr_summary['Active Branches']
                health_overview['Stale Branches'] = pr_summary['Stale Branches']
            
            # Ensure Health Percentage column exists, calculate if needed
            if 'Health Percentage' in pr_summary.columns:
                health_overview.loc[:, 'Health Percentage'] = pr_summary['Health Percentage'].values
            else:
                # Calculate health percentage safely
                health_overview.loc[:, 'Health Percentage'] = (
                    health_overview['Healthy PRs'] / health_overview['Total PRs'] * 100
                ).fillna(0).round(1)
            
            health_overview = health_overview.sort_values(by='Health Percentage', ascending=False)
            
            # Format the health percentage as a string with % sign for display
            health_overview.loc[:, 'Health Score'] = health_overview['Health Percentage'].apply(lambda x: f"{x}%")
            
            # Add a visual indicator of health (emoji only, no text)
            def health_indicator(percentage, total_prs):
                # Special case for repositories with no PRs
                if total_prs == 0:
                    return "âšª"  # White circle for Stable/No Dev repositories
                
                # Regular health indicators (emoji only, no text)
                if percentage >= 80:
                    return "ðŸŸ¢"  # Green circle
                elif percentage >= 50:
                    return "ðŸŸ¡"  # Yellow circle
                else:
                    return "ðŸ”´"  # Red circle
            
            # Apply the indicator with total PRs information
            health_overview.loc[:, 'Status'] = health_overview.apply(
                lambda row: health_indicator(row['Health Percentage'], row['Total PRs']), 
                axis=1
            )
            
            # Display columns based on availability
            display_columns = ['Repository', 'Total PRs', 'Healthy PRs', 'Needs Attention PRs', 'Health Score', 'Status']
            
            # Add branch columns if available
            if 'Total Branches' in health_overview.columns:
                display_columns.extend(['Total Branches', 'Active Branches', 'Stale Branches'])
                
            # Display the table
            st.dataframe(
                health_overview[display_columns], 
                use_container_width=True
            )
            
        except Exception as e:
            st.error(f"Error creating overall summary: {str(e)}")
    
    def create_contributor_summary(self, data):
        """Create contributor summary view with complete contributor statistics only."""
        try:
            st.header("Contributor Activity Summary")
            
            contributor_summary = data['contributor_summary']
            
            # Complete Contributor Statistics with filtering
            st.subheader("Complete Contributor Statistics")

            # Create a copy of the contributor summary for display
            complete_stats = contributor_summary.copy()

            # Format health percentage as a string with % sign
            if 'Health Percentage' in complete_stats.columns:
                complete_stats['Health Score'] = complete_stats['Health Percentage'].apply(lambda x: f"{x}%")

            # Create a health status indicator
            if 'Health Percentage' in complete_stats.columns:
                def health_status_indicator(percentage, total_prs=None):
                    # Special case for contributors with no PRs
                    if total_prs is not None and total_prs == 0:
                        return "âšª"  # White circle for no activity
                    
                    # Regular health indicators (emoji only, no text)
                    if percentage >= 80:
                        return "ðŸŸ¢"  # Green circle
                    elif percentage >= 50:
                        return "ðŸŸ¡"  # Yellow circle
                    else:
                        return "ðŸ”´"  # Red circle
                
                if 'Total PRs' in complete_stats.columns:
                    complete_stats['Health Status'] = complete_stats.apply(
                        lambda row: health_status_indicator(row['Health Percentage'], row['Total PRs']),
                        axis=1
                    )
                else:
                    complete_stats['Health Status'] = complete_stats['Health Percentage'].apply(health_status_indicator)

            # Add check success rate if checks data is available
            if all(col in complete_stats.columns for col in ['Passed Checks', 'Failed Checks']):
                def calculate_success_rate(row):
                    if (row['Passed Checks'] + row['Failed Checks']) > 0:
                        rate = round((row['Passed Checks'] / (row['Passed Checks'] + row['Failed Checks']) * 100), 1)
                        return f"{rate}%"
                    else:
                        return "N/A"
                        
                complete_stats['Check Success Rate'] = complete_stats.apply(calculate_success_rate, axis=1)

            # Select columns for display 
            display_cols = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits']

            # Add branch metrics columns if available
            branch_cols = ['Total Branches', 'Active Branches', 'Stale Branches']
            for col in branch_cols:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Add health-related columns if available
            health_cols = ['Healthy PRs', 'Unhealthy PRs', 'Health Score', 'Health Status']
            display_cols.extend([col for col in health_cols if col in complete_stats.columns])

            # Add new commit check metrics if available
            for col in ['Total Commit Passed Checks', 'Total Commit Failed Checks', 'Avg Passed Checks per PR', 'Avg Failed Checks per PR']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Add breaking change column if available
            if 'Breaking Change PRs' in complete_stats.columns:
                display_cols.append('Breaking Change PRs')
            
            # Add comment metrics if available
            for col in ['Total Reviewer Comments', 'Total Approver Comments', 'Total Resolved Conversations', 'Total Unresolved Conversations']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Add feature/fix coverage metrics if available
            for col in ['Feature/Fix PRs', 'With Examples', 'With Tests', 'With Integration Tests',
                    'Examples Coverage (%)', 'Tests Coverage (%)', 'Integration Tests Coverage (%)']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Rename Unhealthy PRs to Needs Attention PRs for display
            if 'Unhealthy PRs' in display_cols:
                complete_stats = complete_stats.rename(columns={'Unhealthy PRs': 'Needs Attention PRs'})
                # Update the display columns list
                display_cols = [col if col != 'Unhealthy PRs' else 'Needs Attention PRs' for col in display_cols]

            # Add version type columns if available
            version_cols = ['RC Versions', 'NPD Versions', 'Stable Versions']
            display_cols.extend([col for col in version_cols if col in complete_stats.columns])

            # Add check status columns if available
            check_cols = ['Passed Checks', 'Failed Checks', 'Check Success Rate']
            display_cols.extend([col for col in check_cols if col in complete_stats.columns])

            # Add filtering options
            st.write("Filter contributors:")
            col1, col2, col3 = st.columns(3)

            with col1:
                # Filter by contributor name
                search_term = st.text_input("Search by contributor name:", "", key="search_contributor")
                if search_term:
                    complete_stats = complete_stats[complete_stats['Contributor'].str.contains(search_term, case=False)]

            with col2:
                # Filter by minimum PRs
                min_prs = st.number_input("Minimum PRs:", min_value=0, value=0, key="min_prs")
                if min_prs > 0:
                    complete_stats = complete_stats[complete_stats['Total PRs'] >= min_prs]

            with col3:
                # Filter by health status
                if 'Health Status' in complete_stats.columns:
                    health_options = ["All"] + sorted(complete_stats['Health Status'].unique().tolist())
                    selected_health = st.selectbox("Health Status:", health_options, key="health_status")
                    if selected_health != "All":
                        complete_stats = complete_stats[complete_stats['Health Status'] == selected_health]

            # Add second row of filters
            col1, col2, col3 = st.columns(3)

            with col1:
                # Filter by repository count
                if 'Repositories' in complete_stats.columns:
                    min_repos = st.number_input("Minimum Repositories:", min_value=0, value=0, key="min_repos")
                    if min_repos > 0:
                        complete_stats = complete_stats[complete_stats['Repositories'] >= min_repos]

            with col2:
                # Filter by minimum commits
                min_commits = st.number_input("Minimum Commits:", min_value=0, value=0, key="min_commits")
                if min_commits > 0:
                    complete_stats = complete_stats[complete_stats['Total Commits'] >= min_commits]

            with col3:
                # Sort options
                sort_options = {
                    "Total PRs (high to low)": ("Total PRs", False),
                    "Total PRs (low to high)": ("Total PRs", True),
                    "Total Commits (high to low)": ("Total Commits", False),
                    "Total Commits (low to high)": ("Total Commits", True),
                    "Contributor (A-Z)": ("Contributor", True),
                    "Contributor (Z-A)": ("Contributor", False),
                }
                                
                # Add new sort options for branches
                if 'Total Branches' in complete_stats.columns:
                    sort_options["Total Branches (high to low)"] = ("Total Branches", False)
                    sort_options["Active Branches (high to low)"] = ("Active Branches", False)
                    sort_options["Stale Branches (high to low)"] = ("Stale Branches", False)
                
                # Add new sort options for commit checks
                if 'Total Commit Passed Checks' in complete_stats.columns:
                    sort_options["Commit Passed Checks (high to low)"] = ("Total Commit Passed Checks", False)
                
                if 'Avg Passed Checks per PR' in complete_stats.columns:
                    sort_options["Avg Passed Checks per PR (high to low)"] = ("Avg Passed Checks per PR", False)
                
                if 'Health Percentage' in complete_stats.columns:
                    sort_options["Health (high to low)"] = ("Health Percentage", False)
                    sort_options["Health (low to high)"] = ("Health Percentage", True)
                
                if 'Breaking Change PRs' in complete_stats.columns:
                    sort_options["Breaking Changes (high to low)"] = ("Breaking Change PRs", False)
                
                if 'Total Reviewer Comments' in complete_stats.columns:
                    sort_options["Comments (high to low)"] = ("Total Reviewer Comments", False)
                
                selected_sort = st.selectbox("Sort by:", list(sort_options.keys()), index=0, key="sort_option")
                sort_column, sort_ascending = sort_options[selected_sort]
                
                if sort_column in complete_stats.columns:
                    complete_stats = complete_stats.sort_values(by=sort_column, ascending=sort_ascending)

            # Add third row of filters specific for branch metrics
            if any(col in complete_stats.columns for col in branch_cols):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    # Filter by minimum total branches
                    if 'Total Branches' in complete_stats.columns:
                        min_branches = st.number_input("Minimum Total Branches:", min_value=0, value=0, key="min_branches")
                        if min_branches > 0:
                            complete_stats = complete_stats[complete_stats['Total Branches'] >= min_branches]
                
                with col2:
                    # Filter by minimum active branches
                    if 'Active Branches' in complete_stats.columns:
                        min_active = st.number_input("Minimum Active Branches:", min_value=0, value=0, key="min_active")
                        if min_active > 0:
                            complete_stats = complete_stats[complete_stats['Active Branches'] >= min_active]
                
                with col3:
                    # Filter by minimum stale branches
                    if 'Stale Branches' in complete_stats.columns:
                        min_stale = st.number_input("Minimum Stale Branches:", min_value=0, value=0, key="min_stale")
                        if min_stale > 0:
                            complete_stats = complete_stats[complete_stats['Stale Branches'] >= min_stale]

            # Make sure all display columns exist in the dataframe
            display_cols = [col for col in display_cols if col in complete_stats.columns]

            # Display the filtered and sorted table
            if complete_stats.empty:
                st.warning("No contributors match the selected filters.")
            else:
                st.write(f"Showing {len(complete_stats)} contributors")
                if not display_cols:
                    st.warning("No contributor data columns available for display")
                else:
                    st.dataframe(
                        complete_stats[display_cols],
                        use_container_width=True
                    )
            
        except Exception as e:
            st.error(f"Error creating contributor summary: {str(e)}")
    
    def run(self):
        """Run the dashboard application."""
        # Add sidebar for configuration
        with st.sidebar:
            st.header("GitHub Metrics Dashboard")
            st.markdown("---")
            
            # Add report directory selector
            st.subheader("Report Selection")
            report_dirs = self.scan_for_report_directories()
            
            if not report_dirs:
                st.warning("No report directories or files found.")
                custom_dir = st.text_input("Enter custom report directory or path:")
            else:
                # Create formatted options for selection
                report_options = self.create_report_options(report_dirs)
                
                if not report_options:
                    st.warning("No valid reports found in any directories.")
                    custom_dir = st.text_input("Enter custom report directory or path:")
                else:
                    # Get the default (latest) directory
                    default_dir = self.find_latest_report()
                    default_idx = next((i for i, (_, dir_name) in enumerate(report_options) if dir_name == default_dir), 0)
                    
                    # Create selection box
                    selected_report = st.selectbox(
                        "Select report:",
                        [name for name, _ in report_options],
                        index=min(default_idx, len(report_options) - 1) if report_options else 0
                    )
                    
                    # Get the corresponding directory
                    custom_dir = next((dir_name for name, dir_name in report_options if name == selected_report), None)
            
            # Always allow manual entry of a custom directory
            if st.checkbox("Specify custom directory", value=False):
                custom_input = st.text_input("Enter custom report directory or path:")
                if custom_input:
                    custom_dir = custom_input
            
            st.markdown("---")
            st.markdown("### About")
            st.markdown("This dashboard visualizes GitHub metrics generated by the GitHub Metrics Reporter.")
        
        # Load report data
        data, report_dir = self.load_report_data(custom_dir)
        
        if not data:
            st.error("No data available. Please select a valid report directory.")
            return
        
        # Create tabs for different views (simplified)
        tab1, tab2 = st.tabs(["Overall Summary", "Contributor Summary"])
        
        with tab1:
            self.create_overall_summary(data)
            
        with tab2:
            # Extract date ranges from PR data for filtering
            pr_activity = data['pr_activity']
            
            # Extract min and max dates
            min_date = datetime.now()
            max_date = datetime(2000, 1, 1)
            
            if 'Created Date' in pr_activity.columns:
                # Parse dates if they're strings
                if isinstance(pr_activity['Created Date'].iloc[0], str):
                    pr_activity['Created Date'] = pd.to_datetime(pr_activity['Created Date'])
                
                date_col = 'Created Date'
                min_date = pr_activity[date_col].min()
                max_date = pr_activity[date_col].max()
                
                # Add weekly range filter to contributor tab
                st.markdown("## Date Range Filter")
                start_date, end_date = self.add_weekly_range_filter(min_date, max_date, section_key="contributor")
                
                # Filter contributor data based on PRs in the selected date range
                # Find PRs within date range
                filtered_prs = pr_activity[(pr_activity[date_col] >= pd.Timestamp(start_date)) & 
                                        (pr_activity[date_col] <= pd.Timestamp(end_date))]
                
                # Get unique contributors in filtered PRs
                filtered_contributors = filtered_prs['Author'].unique()
                
                # Filter contributor summary
                filtered_contributor_summary = data['contributor_summary'][
                    data['contributor_summary']['Contributor'].isin(filtered_contributors)
                ]
                
                # Create a copy of data with filtered contributors
                filtered_data = data.copy()
                filtered_data['contributor_summary'] = filtered_contributor_summary
                
                # Display filtered data
                self.create_contributor_summary(filtered_data)
            else:
                # If date column not available, show unfiltered data
                self.create_contributor_summary(data)

if __name__ == "__main__":
    dashboard = GitHubMetricsDashboard()
    dashboard.run()