#!/usr/bin/env python3
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime
import pytz
import re

class GitHubMetricsDashboard:
    """
    Streamlit dashboard for visualizing GitHub repository metrics reports.
    Displays summary information from Excel reports generated by the GitHub Metrics Reporter.
    """
    
    def __init__(self):
        """Initialize dashboard with configuration and setup."""
        self.utc = pytz.UTC
        self.reports_root = 'reports_*'  # Pattern to find report directories
        self.custom_output_dirs = ['output', 'outputs', 'report', 'reports']  # Common custom output directories
        self.latest_report_dir = None
        
        # Set page configuration
        st.set_page_config(
            page_title="GitHub Metrics Dashboard",
            page_icon="📊",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # Set title
        st.title("GitHub Repository Metrics Dashboard")
    
    def find_latest_report(self):
        """Find the most recent report directory based on timestamp in directory name or file modification time."""
        try:
            # Start with default report directories (reports_*)
            report_dirs = glob.glob(self.reports_root)
            
            # Add custom output directories if they exist
            for custom_dir in self.custom_output_dirs:
                if os.path.isdir(custom_dir):
                    report_dirs.append(custom_dir)
            
            if not report_dirs:
                st.error("No report directories found. Please generate reports first.")
                return None
                
            # Track potential report directories with their timestamps
            timestamps = []
            
            for dir_name in report_dirs:
                # Check if this is a timestamped reports directory
                match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
                if match:
                    timestamp_str = match.group(1)
                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                        timestamps.append((timestamp, dir_name))
                        continue
                    except ValueError:
                        pass  # Not a valid timestamp format, will check for Excel files below
                
                # Check if Excel report files exist in this directory
                pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(dir_name, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    # Use the most recent modification time as the timestamp
                    pr_mtime = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                    contrib_mtime = datetime.fromtimestamp(os.path.getmtime(contributor_report_path))
                    timestamp = max(pr_mtime, contrib_mtime)
                    timestamps.append((timestamp, dir_name))
            
            if not timestamps:
                st.error("No valid report directories or files found.")
                return None
                
            # Get the most recent directory
            latest = max(timestamps, key=lambda x: x[0])
            return latest[1]
            
        except Exception as e:
            st.error(f"Error finding report directory: {str(e)}")
            return None
    
    def scan_for_report_directories(self):
        """Scan for all potential directories containing reports."""
        # Start with default report directories (reports_*)
        report_dirs = glob.glob(self.reports_root)
        
        # Add custom output directories if they exist and contain report files
        for custom_dir in self.custom_output_dirs:
            if os.path.isdir(custom_dir):
                pr_report_path = os.path.join(custom_dir, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(custom_dir, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    report_dirs.append(custom_dir)
        
        # Also check current directory for report files
        pr_report_path = 'pr_activity_report.xlsx'
        contributor_report_path = 'contributor_report.xlsx'
        if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
            report_dirs.append('.')
            
        return report_dirs
    
    def create_report_options(self, report_dirs):
        """Create formatted options for report selection dropdown."""
        report_options = []
        
        for dir_name in report_dirs:
            # First try to extract timestamp from directory name
            match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
            if match:
                timestamp_str = match.group(1)
                try:
                    timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                    report_options.append((readable_name, dir_name, timestamp))
                    continue
                except ValueError:
                    pass  # Invalid timestamp format, fall back to file modification time
            
            # Use file modification time for other directories
            pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
            if os.path.exists(pr_report_path):
                timestamp = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                if dir_name == '.':
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} (Current Directory)"
                else:
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                report_options.append((readable_name, dir_name, timestamp))
        
        # Sort by timestamp (newest first)
        report_options.sort(key=lambda x: x[2], reverse=True)
        return [(name, dir_name) for name, dir_name, _ in report_options]
    
    def load_report_data(self, custom_dir=None):
        """Load data from Excel reports in the specified or latest directory."""
        try:
            # Find the latest report directory if none specified
            report_dir = custom_dir if custom_dir else self.find_latest_report()
            if not report_dir:
                return None, None
                
            self.latest_report_dir = report_dir
            
            # Construct file paths
            pr_report_path = os.path.join(report_dir, 'pr_activity_report.xlsx')
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if files exist
            if not os.path.exists(pr_report_path) or not os.path.exists(contributor_report_path):
                st.error(f"Required report files not found in {report_dir}")
                return None, None
                
            # Load PR Activity data
            pr_summary_df = pd.read_excel(pr_report_path, sheet_name='Repository Summary')
            pr_activity_df = pd.read_excel(pr_report_path, sheet_name='PR Activity')
            
            # Load Contributor data
            contributor_summary_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Summary')
            contributor_detail_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Metrics')
            
            # Return data package
            return {
                'pr_summary': pr_summary_df,
                'pr_activity': pr_activity_df,
                'contributor_summary': contributor_summary_df,
                'contributor_detail': contributor_detail_df
            }, report_dir
            
        except Exception as e:
            st.error(f"Error loading report data: {str(e)}")
            return None, None
    
    def create_overall_summary(self, data):
        """Create overall summary metrics from the report data."""
        try:
            st.header("Overall Repository Health Summary")
            
            pr_summary = data['pr_summary']
            contributor_summary = data['contributor_summary']
            
            # Display report timestamp
            if self.latest_report_dir:
                match = re.search(r'reports_(\d{8}_\d{6})', self.latest_report_dir)
                if match:
                    timestamp_str = match.group(1)
                    report_date = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    st.info(f"Report generated on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
                else:
                    # For non-timestamped directories, use the modification time of PR report
                    pr_report_path = os.path.join(self.latest_report_dir, 'pr_activity_report.xlsx')
                    if os.path.exists(pr_report_path):
                        report_date = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                        st.info(f"Report last modified on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Create metrics columns
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    label="Total Repositories", 
                    value=len(pr_summary)
                )
                
                st.metric(
                    label="Total Contributors", 
                    value=len(contributor_summary)
                )
            
            with col2:
                total_prs = pr_summary['Total PRs'].sum()
                merged_prs = pr_summary['Merged PRs'].sum()
                
                st.metric(
                    label="Total PRs", 
                    value=total_prs
                )
                
                merge_percentage = round((merged_prs / total_prs) * 100, 1) if total_prs > 0 else 0
                st.metric(
                    label="Merged PRs", 
                    value=merged_prs,
                    delta=f"{merge_percentage}%"
                )
            
            with col3:
                healthy_prs = pr_summary['Healthy PRs'].sum()
                unhealthy_prs = pr_summary['Unhealthy PRs'].sum()
                
                st.metric(
                    label="Healthy PRs", 
                    value=healthy_prs
                )
                
                st.metric(
                    label="Unhealthy PRs", 
                    value=unhealthy_prs,
                    delta="-" + str(unhealthy_prs),  # Convert to string
                    delta_color="inverse"
                )
            
            with col4:
                # Carefully handle checks data which might be missing or in different formats
                if 'Passed Checks' in pr_summary.columns:
                    if isinstance(pr_summary['Passed Checks'], (int, float)):
                        total_passed = pr_summary['Passed Checks']
                    elif hasattr(pr_summary['Passed Checks'], 'sum'):
                        total_passed = pr_summary['Passed Checks'].sum()
                    else:
                        total_passed = 0
                else:
                    total_passed = 0
                    
                if 'Failed Checks' in pr_summary.columns:
                    if isinstance(pr_summary['Failed Checks'], (int, float)):
                        total_failed = pr_summary['Failed Checks']
                    elif hasattr(pr_summary['Failed Checks'], 'sum'):
                        total_failed = pr_summary['Failed Checks'].sum()
                    else:
                        total_failed = 0
                else:
                    total_failed = 0
                
                st.metric(
                    label="Passed Checks", 
                    value=total_passed
                )
                
                st.metric(
                    label="Failed Checks", 
                    value=total_failed,
                    delta="-" + str(total_failed),  # Convert to string
                    delta_color="inverse"
                )
            
            # Display version type summary
            st.subheader("Version Types Summary")
            col1, col2, col3 = st.columns(3)
            
            # Helper function to safely get version counts
            def get_version_count(column_name):
                if column_name in pr_summary.columns:
                    if isinstance(pr_summary[column_name], (int, float)):
                        return pr_summary[column_name]
                    elif hasattr(pr_summary[column_name], 'sum'):
                        return pr_summary[column_name].sum()
                    else:
                        return 0
                return 0
            
            with col1:
                rc_versions = get_version_count('RC Versions')
                st.metric(label="RC Versions", value=rc_versions)
            
            with col2:
                npd_versions = get_version_count('NPD Versions')
                st.metric(label="NPD Versions", value=npd_versions)
            
            with col3:
                stable_versions = get_version_count('Stable Versions')
                st.metric(label="Stable Versions", value=stable_versions)
            
            # Repository health table
            st.subheader("Repository Health Overview")
            
            # Calculate health percentage for sorting
            health_overview = pr_summary[['Repository', 'Total PRs', 'Healthy PRs', 'Unhealthy PRs']].copy()
            
            # Ensure Health Percentage column exists, calculate if needed
            if 'Health Percentage' in pr_summary.columns:
                health_overview.loc[:, 'Health Percentage'] = pr_summary['Health Percentage'].values
            else:
                # Calculate health percentage safely
                health_overview.loc[:, 'Health Percentage'] = (
                    health_overview['Healthy PRs'] / health_overview['Total PRs'] * 100
                ).fillna(0).round(1)
            
            health_overview = health_overview.sort_values(by='Health Percentage', ascending=False)
            
            # Format the health percentage as a string with % sign for display
            health_overview.loc[:, 'Health Score'] = health_overview['Health Percentage'].apply(lambda x: f"{x}%")
            
            # Add a visual indicator of health
            def health_indicator(percentage):
                if percentage >= 80:
                    return "🟢 Good"
                elif percentage >= 50:
                    return "🟡 Moderate"
                else:
                    return "🔴 Poor"
            
            health_overview.loc[:, 'Status'] = health_overview['Health Percentage'].apply(health_indicator)
            
            # Display the table
            st.dataframe(
                health_overview[['Repository', 'Total PRs', 'Healthy PRs', 'Unhealthy PRs', 'Health Score', 'Status']], 
                use_container_width=True
            )
            
        except Exception as e:
            st.error(f"Error creating overall summary: {str(e)}")
    
    def create_pr_summary(self, data):
        """Create PR activity summary view."""
        try:
            st.header("Pull Request Activity Summary")
            
            pr_summary = data['pr_summary']
            pr_activity = data['pr_activity']
            
            # High-level PR metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                avg_duration = pr_summary['Avg PR Duration (days)'].mean()
                st.metric(
                    label="Average PR Duration (days)", 
                    value=round(avg_duration, 1)
                )
            
            with col2:
                # Check if the columns exist before using them
                if all(col in pr_summary.columns for col in ['PRs With Comments', 'PRs Without Comments']):
                    prs_with_comments = pr_summary['PRs With Comments'].sum()
                    prs_without_comments = pr_summary['PRs Without Comments'].sum()
                    total_prs = prs_with_comments + prs_without_comments
                    
                    if total_prs > 0:
                        comment_percentage = round((prs_with_comments / total_prs) * 100, 1)
                    else:
                        comment_percentage = 0
                    
                    st.metric(
                        label="PRs With Comments", 
                        value=prs_with_comments,
                        delta=f"{comment_percentage}% of total"
                    )
                else:
                    st.metric(
                        label="PRs With Comments", 
                        value="N/A"
                    )
            
            with col3:
                if 'Total Change Requests' in pr_summary.columns:
                    change_requests = pr_summary['Total Change Requests'].sum()
                    st.metric(
                        label="Total Change Requests", 
                        value=change_requests
                    )
                else:
                    st.metric(
                        label="Total Change Requests", 
                        value="N/A"
                    )
            
            # Version Type Distribution
            if all(col in pr_summary.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Type Distribution")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    rc_versions = pr_summary['RC Versions'].sum()
                    st.metric(
                        label="RC Versions", 
                        value=rc_versions
                    )
                
                with col2:
                    npd_versions = pr_summary['NPD Versions'].sum()
                    st.metric(
                        label="NPD Versions", 
                        value=npd_versions
                    )
                
                with col3:
                    stable_versions = pr_summary['Stable Versions'].sum()
                    st.metric(
                        label="Stable Versions", 
                        value=stable_versions
                    )
                
            # PR Health by Repository
            st.subheader("PR Health by Repository")
            
            # Make sure the PR Health column exists and is properly formatted
            if 'PR Health' in pr_activity.columns:
                # Group PR activity data by repository and PR health
                # Extract the health status (Healthy/Unhealthy) by removing the emoji if present
                try:
                    health_by_repo = pd.crosstab(
                        pr_activity['Repository'], 
                        pr_activity['PR Health'].apply(lambda x: x.strip().split(' ')[1] if ' ' in x else x),
                        margins=False
                    )
                    
                    # Rename columns for better display
                    if 'Healthy' in health_by_repo.columns:
                        health_by_repo = health_by_repo.rename(columns={'Healthy': '✅ Healthy'})
                    if 'Unhealthy' in health_by_repo.columns:
                        health_by_repo = health_by_repo.rename(columns={'Unhealthy': '❌ Unhealthy'})
                    
                    # Add total column
                    health_by_repo['Total PRs'] = health_by_repo.sum(axis=1)
                    
                    # Calculate health percentage
                    healthy_col = '✅ Healthy' if '✅ Healthy' in health_by_repo.columns else None
                    if healthy_col:
                        health_by_repo['Health %'] = (health_by_repo[healthy_col] / health_by_repo['Total PRs'] * 100).round(1)
                        health_by_repo['Health %'] = health_by_repo['Health %'].fillna(0)
                        
                        # Sort by health percentage
                        health_by_repo = health_by_repo.sort_values(by='Health %', ascending=False)
                    
                    # Display the table
                    st.dataframe(health_by_repo, use_container_width=True)
                except Exception as e:
                    st.error(f"Error processing PR health data: {str(e)}")
                    # Fallback to simpler grouping
                    repo_counts = pr_activity.groupby('Repository').size().reset_index(name='Total PRs')
                    st.dataframe(repo_counts, use_container_width=True)
            else:
                st.warning("PR Health data not available in the report.")
                repo_counts = pr_activity.groupby('Repository').size().reset_index(name='Total PRs')
                st.dataframe(repo_counts, use_container_width=True)
            
            # PR Checks Status by Repository
            if all(col in pr_activity.columns for col in ['Passed Checks', 'Failed Checks']):
                st.subheader("PR Checks Status by Repository")
                
                # Group PR activity data by repository and calculate check success metrics
                checks_by_repo = pr_activity.groupby('Repository', observed=True).agg({
                    'Passed Checks': 'sum',
                    'Failed Checks': 'sum'
                }).reset_index()
                
                # Calculate total checks and success rate
                checks_by_repo['Total Checks'] = checks_by_repo['Passed Checks'] + checks_by_repo['Failed Checks']
                checks_by_repo['Success Rate (%)'] = (checks_by_repo['Passed Checks'] / checks_by_repo['Total Checks'] * 100).round(1)
                
                # Replace NaN with 0 for repositories with no checks
                checks_by_repo = checks_by_repo.fillna(0)
                
                # Sort by success rate
                checks_by_repo = checks_by_repo.sort_values(by='Success Rate (%)', ascending=False)
                
                # Display the table
                st.dataframe(checks_by_repo, use_container_width=True)
                
            # Version Types by Repository
            if all(col in pr_activity.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Types by Repository")
                
                # Group PR activity data by repository and calculate version type metrics
                versions_by_repo = pr_activity.groupby('Repository', observed=True).agg({
                    'RC Versions': 'sum',
                    'NPD Versions': 'sum',
                    'Stable Versions': 'sum'
                }).reset_index()
                
                # Add total versions column
                versions_by_repo['Total Versions'] = versions_by_repo['RC Versions'] + versions_by_repo['NPD Versions'] + versions_by_repo['Stable Versions']
                
                # Calculate percentages
                for version_type in ['RC Versions', 'NPD Versions', 'Stable Versions']:
                    versions_by_repo[f'{version_type} (%)'] = (versions_by_repo[version_type] / versions_by_repo['Total Versions'] * 100).round(1)
                
                # Replace NaN with 0 for repositories with no versions
                versions_by_repo = versions_by_repo.fillna(0)
                
                # Sort by stable version percentage
                versions_by_repo = versions_by_repo.sort_values(by='Stable Versions (%)', ascending=False)
                
                # Display the table
                st.dataframe(versions_by_repo, use_container_width=True)
            
            # PR Age Distribution
            st.subheader("PR Age Distribution")
            
            # Make sure the Days Open column exists
            if 'Days Open' in pr_activity.columns:
                # Create bins for PR duration
                bins = [0, 1, 3, 7, 14, 30, float('inf')]
                labels = ['1 day or less', '1-3 days', '3-7 days', '7-14 days', '14-30 days', 'Over 30 days']
                
                pr_activity['Age Group'] = pd.cut(pr_activity['Days Open'], bins=bins, labels=labels)
                
                # Group by age
                age_distribution = pr_activity.groupby('Age Group').size().reset_index(name='Count')
                
                # Fill in missing groups with zero count
                all_groups = pd.DataFrame({'Age Group': labels})
                age_distribution = pd.merge(all_groups, age_distribution, on='Age Group', how='left').fillna(0)
                age_distribution['Count'] = age_distribution['Count'].astype(int)
                
                # Calculate percentage
                total_prs = age_distribution['Count'].sum()
                if total_prs > 0:
                    age_distribution.loc[:, 'Percentage'] = (age_distribution['Count'] / total_prs * 100).round(1)
                else:
                    age_distribution.loc[:, 'Percentage'] = 0
                
                # Display as a table
                st.dataframe(age_distribution, use_container_width=True)
            else:
                st.warning("PR age data not available in the report.")
            
        except Exception as e:
            st.error(f"Error creating PR summary: {str(e)}")
    
    def create_contributor_summary(self, data):
        """Create contributor summary view."""
        try:
            st.header("Contributor Activity Summary")
            
            contributor_summary = data['contributor_summary']
            contributor_detail = data['contributor_detail']
            
            # High-level contributor metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                total_contributors = len(contributor_summary)
                multi_repo_contributors = contributor_summary[contributor_summary['Repositories'] > 1].shape[0]
                
                st.metric(
                    label="Total Contributors", 
                    value=total_contributors
                )
                
                if total_contributors > 0:
                    multi_repo_percentage = round((multi_repo_contributors / total_contributors) * 100, 1)
                    st.metric(
                        label="Multi-Repo Contributors", 
                        value=multi_repo_contributors,
                        delta=f"{multi_repo_percentage}% of total"
                    )
                else:
                    st.metric(
                        label="Multi-Repo Contributors", 
                        value=0,
                        delta="0% of total"
                    )
            
            with col2:
                total_commits = contributor_summary['Total Commits'].sum()
                avg_commits_per_contributor = round(total_commits / total_contributors, 1) if total_contributors > 0 else 0
                
                st.metric(
                    label="Total Commits", 
                    value=total_commits
                )
                
                st.metric(
                    label="Avg Commits per Contributor", 
                    value=avg_commits_per_contributor
                )
            
            with col3:
                total_prs = contributor_summary['Total PRs'].sum()
                avg_prs_per_contributor = round(total_prs / total_contributors, 1) if total_contributors > 0 else 0
                
                st.metric(
                    label="Total PRs", 
                    value=total_prs
                )
                
                st.metric(
                    label="Avg PRs per Contributor", 
                    value=avg_prs_per_contributor
                )
            
            # Check Status Metrics
            if all(col in contributor_summary.columns for col in ['Passed Checks', 'Failed Checks']):
                st.subheader("Check Status Metrics")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    passed_checks = contributor_summary['Passed Checks'].sum()
                    st.metric(
                        label="Total Passed Checks", 
                        value=passed_checks
                    )
                
                with col2:
                    failed_checks = contributor_summary['Failed Checks'].sum()
                    st.metric(
                        label="Total Failed Checks", 
                        value=failed_checks
                    )
                
                with col3:
                    success_rate = 0
                    if (passed_checks + failed_checks) > 0:
                        success_rate = round((passed_checks / (passed_checks + failed_checks)) * 100, 1)
                    
                    st.metric(
                        label="Check Success Rate", 
                        value=f"{success_rate}%"
                    )
            
            # Version Type Distribution
            if all(col in contributor_summary.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Type Distribution")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    rc_versions = contributor_summary['RC Versions'].sum()
                    st.metric(
                        label="RC Versions", 
                        value=rc_versions
                    )
                
                with col2:
                    npd_versions = contributor_summary['NPD Versions'].sum()
                    st.metric(
                        label="NPD Versions", 
                        value=npd_versions
                    )
                
                with col3:
                    stable_versions = contributor_summary['Stable Versions'].sum()
                    st.metric(
                        label="Stable Versions", 
                        value=stable_versions
                    )
            
            # Top contributors by PR count
            st.subheader("Top 10 Contributors by PR Count")
            
            # Sort and get top 10
            top_contributors = contributor_summary.sort_values(by='Total PRs', ascending=False).head(10)
            
            # Ensure all required columns exist
            required_columns = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits', 'Health Percentage']
            for col in required_columns:
                if col not in top_contributors.columns:
                    if col == 'Health Percentage':
                        # Calculate it if not present
                        if 'Healthy PRs' in top_contributors.columns and 'Total PRs' in top_contributors.columns:
                            top_contributors['Health Percentage'] = (top_contributors['Healthy PRs'] / top_contributors['Total PRs'] * 100).round(1)
                            top_contributors['Health Percentage'] = top_contributors['Health Percentage'].fillna(0)
                        else:
                            top_contributors['Health Percentage'] = 0
                    else:
                        top_contributors[col] = 0
            
            # Add check status columns if they exist
            display_columns = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits', 'Health Score']
            
            # Create formatted health score
            top_contributors['Health Score'] = top_contributors['Health Percentage'].apply(lambda x: f"{x}%")
            
            # Add version and check data if available
            if all(col in top_contributors.columns for col in ['Passed Checks', 'Failed Checks']):
                def calculate_success_rate(row):
                    if (row['Passed Checks'] + row['Failed Checks']) > 0:
                        rate = round((row['Passed Checks'] / (row['Passed Checks'] + row['Failed Checks']) * 100), 1)
                        return f"{rate}%"
                    else:
                        return "N/A"
                        
                top_contributors['Check Success Rate'] = top_contributors.apply(calculate_success_rate, axis=1)
                display_columns.append('Check Success Rate')
            
            # Add version type counts if available
            for version_type in ['RC Versions', 'NPD Versions', 'Stable Versions']:
                if version_type in top_contributors.columns:
                    display_columns.append(version_type)
            
            # Display the table
            st.dataframe(
                top_contributors[display_columns], 
                use_container_width=True
            )
            
            # Contributor Health Summary
            st.subheader("Contributor Health Overview")
            
            # Add health status indicator
            def health_status(percentage):
                if percentage >= 80:
                    return "🟢 Good"
                elif percentage >= 50:
                    return "🟡 Moderate"
                else:
                    return "🔴 Poor"
            
            contributor_health = contributor_summary.copy()
            contributor_health['Health Status'] = contributor_health['Health Percentage'].apply(health_status)
            
            # Group by health status with observed=True
            health_counts = contributor_health.groupby('Health Status', observed=True).size().reset_index(name='Count')
            
            # Display as a table
            st.dataframe(health_counts, use_container_width=True)
            
            # Top Contributors by Health
            st.subheader("Top 10 Contributors by Health Score")
            
            # Sort by health percentage
            healthy_contributors = contributor_summary.sort_values(by='Health Percentage', ascending=False).head(10)
            healthy_contributors['Health Score'] = healthy_contributors['Health Percentage'].apply(lambda x: f"{x}%")
            
            # Prepare display columns
            display_columns = ['Contributor', 'Total PRs', 'Healthy PRs', 'Unhealthy PRs', 'Health Score']
            
            # Add version type counts if available
            for version_type in ['RC Versions', 'NPD Versions', 'Stable Versions']:
                if version_type in healthy_contributors.columns:
                    display_columns.append(version_type)
            
            # Add check status if available
            if all(col in healthy_contributors.columns for col in ['Passed Checks', 'Failed Checks']):
                display_columns.extend(['Passed Checks', 'Failed Checks'])
                
                # Add success rate calculation
                def calculate_success_rate(row):
                    if (row['Passed Checks'] + row['Failed Checks']) > 0:
                        rate = round((row['Passed Checks'] / (row['Passed Checks'] + row['Failed Checks']) * 100), 1)
                        return f"{rate}%"
                    else:
                        return "N/A"
                        
                healthy_contributors['Check Success Rate'] = healthy_contributors.apply(calculate_success_rate, axis=1)
                display_columns.append('Check Success Rate')
            
            # Make sure all display columns exist in the dataframe
            display_columns = [col for col in display_columns if col in healthy_contributors.columns]
            
            st.dataframe(
                healthy_contributors[display_columns], 
                use_container_width=True
            )
            
            # Check Status Distribution
            if 'repository' in contributor_detail.columns and 'passed_checks' in contributor_detail.columns and 'failed_checks' in contributor_detail.columns:
                st.subheader("Check Status Distribution by Repository")
                
                # Group by repository and calculate check success rate
                check_by_repo = contributor_detail.groupby('repository', observed=True).agg({
                    'passed_checks': 'sum',
                    'failed_checks': 'sum',
                    'total_commits': 'sum'
                }).reset_index()
                
                # Calculate success rate
                check_by_repo['success_rate'] = check_by_repo.apply(
                    lambda row: round((row['passed_checks'] / (row['passed_checks'] + row['failed_checks'])) * 100, 1) 
                    if (row['passed_checks'] + row['failed_checks']) > 0 else 0, 
                    axis=1
                )
                
                # Sort by success rate
                check_by_repo = check_by_repo.sort_values(by='success_rate', ascending=False)
                
                # Rename columns for display
                check_by_repo = check_by_repo.rename(columns={
                    'repository': 'Repository',
                    'passed_checks': 'Passed Checks',
                    'failed_checks': 'Failed Checks',
                    'total_commits': 'Total Commits',
                    'success_rate': 'Success Rate (%)'
                })
                
                # Display the table
                st.dataframe(check_by_repo, use_container_width=True)
            
        except Exception as e:
            st.error(f"Error creating contributor summary: {str(e)}")
            
    def run(self):
        """Run the dashboard application."""
        # Add sidebar for configuration
        with st.sidebar:
            st.header("GitHub Metrics Dashboard")
            st.markdown("---")
            
            # Add report directory selector
            st.subheader("Report Selection")
            report_dirs = self.scan_for_report_directories()
            
            if not report_dirs:
                st.warning("No report directories or files found.")
                custom_dir = st.text_input("Enter custom report directory or path:")
            else:
                # Create formatted options for selection
                report_options = self.create_report_options(report_dirs)
                
                if not report_options:
                    st.warning("No valid reports found in any directories.")
                    custom_dir = st.text_input("Enter custom report directory or path:")
                else:
                    # Get the default (latest) directory
                    default_dir = self.find_latest_report()
                    default_idx = next((i for i, (_, dir_name) in enumerate(report_options) if dir_name == default_dir), 0)
                    
                    # Create selection box
                    selected_report = st.selectbox(
                        "Select report:",
                        [name for name, _ in report_options],
                        index=min(default_idx, len(report_options) - 1) if report_options else 0
                    )
                    
                    # Get the corresponding directory
                    custom_dir = next((dir_name for name, dir_name in report_options if name == selected_report), None)
            
            # Always allow manual entry of a custom directory
            if st.checkbox("Specify custom directory", value=False):
                custom_input = st.text_input("Enter custom report directory or path:")
                if custom_input:
                    custom_dir = custom_input
            
            st.markdown("---")
            st.markdown("### About")
            st.markdown("This dashboard visualizes GitHub metrics generated by the GitHub Metrics Reporter.")
        
        # Load report data
        data, report_dir = self.load_report_data(custom_dir)
        
        if not data:
            st.error("No data available. Please select a valid report directory.")
            return
        
        # Create tabs for different views
        tab1, tab2, tab3 = st.tabs(["Overall Summary", "Contributor Summary", "PR Activity Summary"])
        
        with tab1:
            self.create_overall_summary(data)
            
        with tab2:
            self.create_contributor_summary(data)
            
        with tab3:
            self.create_pr_summary(data)

if __name__ == "__main__":
    dashboard = GitHubMetricsDashboard()
    dashboard.run()