#!/usr/bin/env python3
import pandas as pd
import os
import argparse
import glob
import logging
from datetime import datetime
import pytz

class ExcelReportProcessor:
    """
    Helper utility to read and process Excel reports generated by the GitHub Metrics Reporter.
    Allows for extracting specific sheets, generating CSV exports, and creating summary data.
    Enhanced to handle branch metrics data.
    """
    
    def __init__(self):
        """Initialize the processor with logging setup."""
        self.utc = pytz.UTC
        self._setup_logging()
        self.logger.info("Excel Report Processor initialized")
    
    def _setup_logging(self):
        """Configure logging for the processor."""
        log_dir = 'logs'
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.now(self.utc).strftime("%Y%m%d_%H%M%S")
        log_file = f'{log_dir}/excel_processor_{timestamp}.log'
        
        file_formatter = logging.Formatter(
            '%(asctime)s UTC - %(levelname)s - [%(name)s] - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_formatter = logging.Formatter('%(message)s')
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8', errors='replace')
        file_handler.setFormatter(file_formatter)
        file_handler.setLevel(logging.DEBUG)
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(console_formatter)
        console_handler.setLevel(logging.INFO)
        
        self.logger = logging.getLogger('ExcelProcessor')
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def find_latest_report_dir(self):
        """Find the most recent report directory based on directory name pattern."""
        try:
            report_dirs = glob.glob('reports_*')
            
            if not report_dirs:
                self.logger.error("No report directories found.")
                return None
            
            # Extract timestamps from directory names
            timestamps = []
            for dir_name in report_dirs:
                # Extract timestamp from directory name (format: reports_YYYYMMDD_HHMMSS)
                if '_' in dir_name:
                    timestamp_str = dir_name.split('_', 1)[1]
                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                        timestamps.append((timestamp, dir_name))
                    except ValueError:
                        # Skip directories with invalid timestamp format
                        continue
            
            if not timestamps:
                self.logger.error("No valid report directories found.")
                return None
            
            # Get the most recent directory
            latest = max(timestamps, key=lambda x: x[0])
            self.logger.info(f"Found latest report directory: {latest[1]}")
            return latest[1]
            
        except Exception as e:
            self.logger.error(f"Error finding report directory: {str(e)}")
            return None
    
    def read_excel_report(self, file_path, sheet_name=None):
        """
        Read an Excel report file into a pandas DataFrame.
        
        Args:
            file_path (str): Path to the Excel file
            sheet_name (str, optional): Specific sheet to read, if None reads all sheets
            
        Returns:
            DataFrame or dict of DataFrames: The report data
        """
        try:
            self.logger.info(f"Reading Excel file: {file_path}")
            
            if not os.path.exists(file_path):
                self.logger.error(f"File not found: {file_path}")
                return None
            
            # Read the specified sheet or all sheets
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            if isinstance(df, dict):
                for sheet, data in df.items():
                    self.logger.info(f"Sheet '{sheet}' has {len(data)} rows and {len(data.columns)} columns")
            else:
                self.logger.info(f"Data has {len(df)} rows and {len(df.columns)} columns")
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error reading Excel file: {str(e)}")
            return None
    
    def export_csv(self, df, output_path):
        """
        Export DataFrame to CSV file.
        
        Args:
            df (DataFrame): The data to export
            output_path (str): Path for the output CSV file
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            self.logger.info(f"Exporting data to CSV: {output_path}")
            
            # Create directory if it doesn't exist
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Write to CSV
            df.to_csv(output_path, index=False)
            
            self.logger.info(f"Successfully exported to {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"Error exporting to CSV: {str(e)}")
            return False
    
    def generate_repository_summary(self, report_dir=None):
        """
        Generate a consolidated repository summary from both PR and contributor reports.
        Now includes branch metrics and stale branch counts.
        
        Args:
            report_dir (str, optional): Directory containing the reports
            
        Returns:
            DataFrame: Consolidated summary data
        """
        try:
            # Find the latest report directory if none specified
            if not report_dir:
                report_dir = self.find_latest_report_dir()
                
            if not report_dir:
                self.logger.error("No report directory specified or found.")
                return None
            
            # Construct file paths
            pr_report_path = os.path.join(report_dir, 'pr_activity_report.xlsx')
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if files exist
            if not os.path.exists(pr_report_path) or not os.path.exists(contributor_report_path):
                self.logger.error(f"Required report files not found in {report_dir}")
                return None
            
            # Read PR summary
            pr_summary = self.read_excel_report(pr_report_path, sheet_name='Repository Summary')
            if pr_summary is None:
                return None
            
            # Read PR activity to get comment and conversation counts if not in PR summary
            pr_activity = self.read_excel_report(pr_report_path, sheet_name='PR Activity')
            if pr_activity is None:
                return None
            
            # Read branch summary if available
            branch_summary = self.read_excel_report(pr_report_path, sheet_name='Branch Summary')
            
            # Read contributor summary
            contributor_summary = self.read_excel_report(contributor_report_path, sheet_name='Contributor Summary')
            if contributor_summary is None:
                return None
            
            # Calculate comment and conversation metrics if they don't exist in the summary
            if all(col in pr_activity.columns for col in ['Total Reviewer Comments', 'Total Approver Comments', 'Total Resolved Conversations', 'Total Unresolved Conversations']):
                if not all(col in pr_summary.columns for col in ['Total Reviewer Comments', 'Total Approver Comments', 'Total Resolved Conversations', 'Total Unresolved Conversations']):
                    # Aggregate from PR activity
                    comment_metrics = pr_activity.groupby('Repository').agg({
                        'Total Reviewer Comments': 'sum',
                        'Total Approver Comments': 'sum',
                        'Total Resolved Conversations': 'sum',
                        'Total Unresolved Conversations': 'sum'
                    }).reset_index()
                    
                    # Merge with PR summary
                    pr_summary = pd.merge(pr_summary, comment_metrics, on='Repository', how='left')
                    pr_summary.fillna(0, inplace=True)
            
            # Calculate breaking change counts if they don't exist in the summary
            if 'Is Breaking Change' in pr_activity.columns and 'Breaking Change PRs' not in pr_summary.columns:
                breaking_changes = pr_activity[pr_activity['Is Breaking Change'] == 'Yes'].groupby('Repository').size().reset_index(name='Breaking Change PRs')
                pr_summary = pd.merge(pr_summary, breaking_changes, on='Repository', how='left')
                pr_summary['Breaking Change PRs'].fillna(0, inplace=True)
            
            # Add branch metrics if available
            branch_metrics = {}
            if branch_summary is not None:
                branch_metrics = {
                    'Total Branches': branch_summary['Total Branches'].sum(),
                    'Active Branches': branch_summary['Active Branches'].sum(),
                    'Stale Branches': branch_summary['Stale Branches'].sum()
                }
            
            # Generate consolidated summary
            summary_data = {
                'Total Repositories': len(pr_summary),
                'Total Contributors': len(contributor_summary),
                'Total PRs': pr_summary['Total PRs'].sum(),
                'Merged PRs': pr_summary['Merged PRs'].sum(),
                'Open PRs': pr_summary['Total PRs'].sum() - pr_summary['Merged PRs'].sum(),
                'Healthy PRs': pr_summary['Healthy PRs'].sum(),
                'Unhealthy PRs': pr_summary['Unhealthy PRs'].sum(),
                'Health Percentage': round(pr_summary['Healthy PRs'].sum() / pr_summary['Total PRs'].sum() * 100, 1) if pr_summary['Total PRs'].sum() > 0 else 0,
                'RC Versions': pr_summary['RC Versions'].sum(),
                'NPD Versions': pr_summary['NPD Versions'].sum(),
                'Stable Versions': pr_summary['Stable Versions'].sum(),
                'Avg PR Duration (days)': round(pr_summary['Avg PR Duration (days)'].mean(), 1),
                'Total Commits': contributor_summary['Total Commits'].sum(),
                'Avg Commits per Contributor': round(contributor_summary['Total Commits'].sum() / len(contributor_summary) if len(contributor_summary) > 0 else 0, 1)
            }
            
            # Add branch metrics to summary if available
            if branch_metrics:
                summary_data.update(branch_metrics)
            
            # Add comment metrics if available
            if 'Total Reviewer Comments' in pr_summary.columns:
                summary_data['Total Reviewer Comments'] = pr_summary['Total Reviewer Comments'].sum()
            
            if 'Total Approver Comments' in pr_summary.columns:
                summary_data['Total Approver Comments'] = pr_summary['Total Approver Comments'].sum()
            
            if 'Total Resolved Conversations' in pr_summary.columns:
                summary_data['Total Resolved Conversations'] = pr_summary['Total Resolved Conversations'].sum()
            
            if 'Total Unresolved Conversations' in pr_summary.columns:
                summary_data['Total Unresolved Conversations'] = pr_summary['Total Unresolved Conversations'].sum()
            
            # Add breaking change counts if available
            if 'Breaking Change PRs' in pr_summary.columns:
                summary_data['Breaking Change PRs'] = pr_summary['Breaking Change PRs'].sum()
            
            # Add new contributor metrics if available
            new_contributor_metrics = [
                'Total Commit Passed Checks',
                'Total Commit Failed Checks',
                'Feature/Fix PRs',
                'With Examples',
                'With Tests',
                'With Integration Tests'
            ]
            
            for metric in new_contributor_metrics:
                if metric in contributor_summary.columns:
                    summary_data[metric] = contributor_summary[metric].sum()
            
            # Create DataFrame from summary data
            summary_df = pd.DataFrame([summary_data])
            
            # Generate output path for summary
            summary_path = os.path.join(report_dir, 'consolidated_summary.csv')
            self.export_csv(summary_df, summary_path)
            
            self.logger.info(f"Generated consolidated summary in {summary_path}")
            return summary_df
            
        except Exception as e:
            self.logger.error(f"Error generating repository summary: {str(e)}")
            return None
    
    def extract_top_contributors(self, report_dir=None, top_n=10):
        """
        Extract the top contributors by PR count.
        
        Args:
            report_dir (str, optional): Directory containing the reports
            top_n (int): Number of top contributors to extract
            
        Returns:
            DataFrame: Top contributors data
        """
        try:
            # Find the latest report directory if none specified
            if not report_dir:
                report_dir = self.find_latest_report_dir()
                
            if not report_dir:
                self.logger.error("No report directory specified or found.")
                return None
            
            # Construct file path
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if file exists
            if not os.path.exists(contributor_report_path):
                self.logger.error(f"Contributor report not found in {report_dir}")
                return None
            
            # Read contributor summary
            contributor_summary = self.read_excel_report(contributor_report_path, sheet_name='Contributor Summary')
            if contributor_summary is None:
                return None
            
            # Sort and get top contributors
            top_contributors = contributor_summary.sort_values(by='Total PRs', ascending=False).head(top_n)
            
            # Generate output path for top contributors
            output_path = os.path.join(report_dir, f'top_{top_n}_contributors.csv')
            self.export_csv(top_contributors, output_path)
            
            self.logger.info(f"Extracted top {top_n} contributors to {output_path}")
            return top_contributors
            
        except Exception as e:
            self.logger.error(f"Error extracting top contributors: {str(e)}")
            return None
    
    def extract_branch_metrics(self, report_dir=None):
        """
        Extract branch metrics summary and generate statistics by repository and contributor.
        
        Args:
            report_dir (str, optional): Directory containing the reports
            
        Returns:
            DataFrame: Branch metrics data
        """
        try:
            # Find the latest report directory if none specified
            if not report_dir:
                report_dir = self.find_latest_report_dir()
                
            if not report_dir:
                self.logger.error("No report directory specified or found.")
                return None
            
            # Construct file paths
            pr_report_path = os.path.join(report_dir, 'pr_activity_report.xlsx')
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if files exist
            if not os.path.exists(pr_report_path) or not os.path.exists(contributor_report_path):
                self.logger.error(f"Required report files not found in {report_dir}")
                return None
            
            # Try to read Branch Summary and Branch Details sheets
            try:
                branch_summary = self.read_excel_report(pr_report_path, sheet_name='Branch Summary')
            except:
                self.logger.warning("Branch Summary sheet not found in PR activity report")
                branch_summary = None
            
            try:
                branch_details = self.read_excel_report(pr_report_path, sheet_name='Branch Details')
            except:
                self.logger.warning("Branch Details sheet not found in PR activity report")
                branch_details = None
            
            # Try to read Contributor Branches sheet
            try:
                contributor_branches = self.read_excel_report(contributor_report_path, sheet_name='Contributor Branches')
            except:
                self.logger.warning("Contributor Branches sheet not found in contributor report")
                contributor_branches = None
            
            # If no branch data available, return None
            if branch_summary is None and branch_details is None and contributor_branches is None:
                self.logger.error("No branch metrics data found in reports")
                return None
            
            # Generate branch metrics summary
            metrics = {}
            
            if branch_summary is not None:
                metrics['total_branches'] = branch_summary['Total Branches'].sum()
                metrics['active_branches'] = branch_summary['Active Branches'].sum()
                metrics['stale_branches'] = branch_summary['Stale Branches'].sum()
            
            # Create DataFrame from metrics
            metrics_df = pd.DataFrame([metrics])
            
            # Generate output path for branch metrics
            output_path = os.path.join(report_dir, 'branch_metrics_summary.csv')
            self.export_csv(metrics_df, output_path)
            
            # Generate detailed metrics by repository
            if branch_summary is not None:
                repo_output_path = os.path.join(report_dir, 'branch_metrics_by_repository.csv')
                self.export_csv(branch_summary, repo_output_path)
            
            # Generate detailed metrics by contributor
            if contributor_branches is not None:
                contrib_output_path = os.path.join(report_dir, 'branch_metrics_by_contributor.csv')
                self.export_csv(contributor_branches, contrib_output_path)
            
            self.logger.info(f"Extracted branch metrics to {output_path}")
            return metrics_df
            
        except Exception as e:
            self.logger.error(f"Error extracting branch metrics: {str(e)}")
            return None

def main():
    parser = argparse.ArgumentParser(description='Process Excel reports generated by GitHub Metrics Reporter')
    parser.add_argument('--dir', help='Directory containing the reports')
    parser.add_argument('--summary', action='store_true', help='Generate consolidated summary')
    parser.add_argument('--top', type=int, default=10, help='Extract top N contributors')
    parser.add_argument('--branches', action='store_true', help='Extract branch metrics')
    args = parser.parse_args()
    
    processor = ExcelReportProcessor()
    
    # Use specified directory or find the latest
    report_dir = args.dir if args.dir else processor.find_latest_report_dir()
    
    if not report_dir:
        print("Error: No report directory specified or found.")
        return
    
    # Generate requested reports
    if args.summary:
        processor.generate_repository_summary(report_dir)
    
    if args.top:
        processor.extract_top_contributors(report_dir, args.top)
    
    if args.branches:
        processor.extract_branch_metrics(report_dir)
    
    # If no specific action requested, generate all
    if not (args.summary or args.top or args.branches):
        processor.generate_repository_summary(report_dir)
        processor.extract_top_contributors(report_dir)
        processor.extract_branch_metrics(report_dir)
    
    print(f"Processing complete for report directory: {report_dir}")

if __name__ == "__main__":
    main()