#!/usr/bin/env python3
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime, timedelta
import pytz
import re

class GitHubMetricsDashboard:
    """
    Streamlit dashboard for visualizing GitHub repository metrics reports.
    Displays summary information from Excel reports generated by the GitHub Metrics Reporter.
    """
    
    def __init__(self):
        """Initialize dashboard with configuration and setup."""
        self.utc = pytz.UTC
        self.reports_root = 'reports_*'  # Pattern to find report directories
        self.custom_output_dirs = ['output', 'outputs', 'report', 'reports']  # Common custom output directories
        self.latest_report_dir = None
        
        # Set page configuration
        st.set_page_config(
            page_title="GitHub Metrics Dashboard",
            page_icon="ðŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # Set title
        st.title("GitHub Repository Metrics Dashboard")
    
    def find_latest_report(self):
        """Find the most recent report directory based on timestamp in directory name or file modification time."""
        try:
            # Start with default report directories (reports_*)
            report_dirs = glob.glob(self.reports_root)
            
            # Add custom output directories if they exist
            for custom_dir in self.custom_output_dirs:
                if os.path.isdir(custom_dir):
                    report_dirs.append(custom_dir)
            
            if not report_dirs:
                st.error("No report directories found. Please generate reports first.")
                return None
                
            # Track potential report directories with their timestamps
            timestamps = []
            
            for dir_name in report_dirs:
                # Check if this is a timestamped reports directory
                match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
                if match:
                    timestamp_str = match.group(1)
                    try:
                        timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                        timestamps.append((timestamp, dir_name))
                        continue
                    except ValueError:
                        pass  # Not a valid timestamp format, will check for Excel files below
                
                # Check if Excel report files exist in this directory
                pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(dir_name, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    # Use the most recent modification time as the timestamp
                    pr_mtime = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                    contrib_mtime = datetime.fromtimestamp(os.path.getmtime(contributor_report_path))
                    timestamp = max(pr_mtime, contrib_mtime)
                    timestamps.append((timestamp, dir_name))
            
            if not timestamps:
                st.error("No valid report directories or files found.")
                return None
                
            # Get the most recent directory
            latest = max(timestamps, key=lambda x: x[0])
            return latest[1]
            
        except Exception as e:
            st.error(f"Error finding report directory: {str(e)}")
            return None
    
    def scan_for_report_directories(self):
        """Scan for all potential directories containing reports."""
        # Start with default report directories (reports_*)
        report_dirs = glob.glob(self.reports_root)
        
        # Add custom output directories if they exist and contain report files
        for custom_dir in self.custom_output_dirs:
            if os.path.isdir(custom_dir):
                pr_report_path = os.path.join(custom_dir, 'pr_activity_report.xlsx')
                contributor_report_path = os.path.join(custom_dir, 'contributor_report.xlsx')
                
                if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
                    report_dirs.append(custom_dir)
        
        # Also check current directory for report files
        pr_report_path = 'pr_activity_report.xlsx'
        contributor_report_path = 'contributor_report.xlsx'
        if os.path.exists(pr_report_path) and os.path.exists(contributor_report_path):
            report_dirs.append('.')
            
        return report_dirs
    
    def create_report_options(self, report_dirs):
        """Create formatted options for report selection dropdown."""
        report_options = []
        
        for dir_name in report_dirs:
            # First try to extract timestamp from directory name
            match = re.search(r'reports_(\d{8}_\d{6})', dir_name)
            if match:
                timestamp_str = match.group(1)
                try:
                    timestamp = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                    report_options.append((readable_name, dir_name, timestamp))
                    continue
                except ValueError:
                    pass  # Invalid timestamp format, fall back to file modification time
            
            # Use file modification time for other directories
            pr_report_path = os.path.join(dir_name, 'pr_activity_report.xlsx')
            if os.path.exists(pr_report_path):
                timestamp = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                if dir_name == '.':
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} (Current Directory)"
                else:
                    readable_name = f"{timestamp.strftime('%Y-%m-%d %H:%M:%S')} ({dir_name})"
                report_options.append((readable_name, dir_name, timestamp))
        
        # Sort by timestamp (newest first)
        report_options.sort(key=lambda x: x[2], reverse=True)
        return [(name, dir_name) for name, dir_name, _ in report_options]
    
    def load_report_data(self, custom_dir=None):
        """Load data from Excel reports in the specified or latest directory."""
        try:
            # Find the latest report directory if none specified
            report_dir = custom_dir if custom_dir else self.find_latest_report()
            if not report_dir:
                return None, None
                
            self.latest_report_dir = report_dir
            
            # Construct file paths
            pr_report_path = os.path.join(report_dir, 'pr_activity_report.xlsx')
            contributor_report_path = os.path.join(report_dir, 'contributor_report.xlsx')
            
            # Check if files exist
            if not os.path.exists(pr_report_path) or not os.path.exists(contributor_report_path):
                st.error(f"Required report files not found in {report_dir}")
                return None, None
                
            # Load PR Activity data
            pr_summary_df = pd.read_excel(pr_report_path, sheet_name='Repository Summary')
            pr_activity_df = pd.read_excel(pr_report_path, sheet_name='PR Activity')
            
            # Load Contributor data
            contributor_summary_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Summary')
            contributor_detail_df = pd.read_excel(contributor_report_path, sheet_name='Contributor Metrics')
            
            # Return data package
            return {
                'pr_summary': pr_summary_df,
                'pr_activity': pr_activity_df,
                'contributor_summary': contributor_summary_df,
                'contributor_detail': contributor_detail_df
            }, report_dir
            
        except Exception as e:
            st.error(f"Error loading report data: {str(e)}")
            return None, None
    
    def add_weekly_range_filter(self, min_date, max_date, default_weeks=4, section_key="default"):
        """Add a weekly range filter to filter data by date."""
        st.subheader("Date Range Filter")
        
        # Calculate default date range (last 4 weeks by default)
        if isinstance(min_date, str):
            min_date = datetime.strptime(min_date, '%Y-%m-%d')
        if isinstance(max_date, str):
            max_date = datetime.strptime(max_date, '%Y-%m-%d')
        
        default_end = max_date
        default_start = max_date - timedelta(weeks=default_weeks)
        # Ensure default_start is not earlier than min_date
        default_start = max(default_start, min_date)
        
        # Create two columns for start and end date inputs
        col1, col2 = st.columns(2)
        
        with col1:
            start_date = st.date_input(
                "Start Date",
                value=default_start,
                min_value=min_date,
                max_value=max_date,
                key=f"start_date_{section_key}"
            )
        
        with col2:
            end_date = st.date_input(
                "End Date",
                value=default_end,
                min_value=min_date,
                max_value=max_date,
                key=f"end_date_{section_key}"
            )
        
        # Add quick selection buttons for common time periods
        st.write("Quick select:")
        col1, col2, col3, col4 = st.columns(4)
        
        # Store the selected period in session state
        if "date_range" not in st.session_state:
            st.session_state.date_range = {}
        
        with col1:
            if st.button("Last Week", key=f"last_week_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=1),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col2:
            if st.button("Last Month", key=f"last_month_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=4),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col3:
            if st.button("Last Quarter", key=f"last_quarter_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": max_date - timedelta(weeks=13),
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        with col4:
            if st.button("All Time", key=f"all_time_{section_key}"):
                st.session_state.date_range[section_key] = {
                    "start": min_date,
                    "end": max_date
                }
                return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        # Check if we have stored dates from buttons
        if section_key in st.session_state.date_range:
            return st.session_state.date_range[section_key]["start"], st.session_state.date_range[section_key]["end"]
        
        # Ensure end_date is not before start_date
        if end_date < start_date:
            st.error("End date must be after start date")
            end_date = start_date
        
        st.markdown("---")
        
        return start_date, end_date
    
    def create_overall_summary(self, data):
        """Create overall summary metrics from the report data."""
        try:
            st.header("Overall Repository Health Summary")
            
            pr_summary = data['pr_summary']
            contributor_summary = data['contributor_summary']
            pr_activity = data['pr_activity']
            
            # Display report timestamp
            if self.latest_report_dir:
                match = re.search(r'reports_(\d{8}_\d{6})', self.latest_report_dir)
                if match:
                    timestamp_str = match.group(1)
                    report_date = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S')
                    st.info(f"Report generated on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
                else:
                    # For non-timestamped directories, use the modification time of PR report
                    pr_report_path = os.path.join(self.latest_report_dir, 'pr_activity_report.xlsx')
                    if os.path.exists(pr_report_path):
                        report_date = datetime.fromtimestamp(os.path.getmtime(pr_report_path))
                        st.info(f"Report last modified on: {report_date.strftime('%Y-%m-%d %H:%M:%S')}")
            
            # Create metrics columns
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    label="Total Repositories", 
                    value=len(pr_summary)
                )
                
                st.metric(
                    label="Total Contributors", 
                    value=len(contributor_summary)
                )
            
            with col2:
                total_prs = pr_summary['Total PRs'].sum()
                merged_prs = pr_summary['Merged PRs'].sum()
                
                st.metric(
                    label="Total PRs", 
                    value=total_prs
                )
                
                merge_percentage = round((merged_prs / total_prs) * 100, 1) if total_prs > 0 else 0
                st.metric(
                    label="Merged PRs", 
                    value=merged_prs,
                    delta=f"{merge_percentage}%"
                )
            
            with col3:
                healthy_prs = pr_summary['Healthy PRs'].sum()
                unhealthy_prs = pr_summary['Unhealthy PRs'].sum()
                
                st.metric(
                    label="Healthy PRs", 
                    value=healthy_prs
                )
                
                st.metric(
                    label="Needs Attention PRs", 
                    value=unhealthy_prs,
                    delta="-" + str(unhealthy_prs),  # Convert to string
                    delta_color="inverse"
                )
            
            with col4:
                # Calculate total passed and failed checks
                total_passed = 0
                total_failed = 0

                # First try to get the values from pr_summary (repository level aggregates)
                if 'Passed Checks' in pr_summary.columns:
                    total_passed = pr_summary['Passed Checks'].sum()
                    
                if 'Failed Checks' in pr_summary.columns:
                    total_failed = pr_summary['Failed Checks'].sum()

                # If the totals are still 0, try to calculate from pr_activity (individual PR level)
                if total_passed == 0 and total_failed == 0 and 'pr_activity' in data:
                    pr_activity = data['pr_activity']
                    if 'Passed Checks' in pr_activity.columns:
                        total_passed = pr_activity['Passed Checks'].sum()
                    if 'Failed Checks' in pr_activity.columns:
                        total_failed = pr_activity['Failed Checks'].sum()

                st.metric(
                    label="Passed Checks", 
                    value=total_passed
                )

                st.metric(
                    label="Failed Checks", 
                    value=total_failed,
                    delta="-" + str(total_failed) if total_failed > 0 else "0",
                    delta_color="inverse" if total_failed > 0 else "normal"
                )
            
            # Add comment and breaking change metrics to overall summary
            st.subheader("Enhanced Metrics Summary")
            col1, col2, col3, col4 = st.columns(4)
            
            total_reviewer_comments = 0
            total_approver_comments = 0
            total_resolved = 0
            total_unresolved = 0
            total_breaking = 0
            
            if 'pr_activity' in data:
                pr_activity = data['pr_activity']
                if 'Total Reviewer Comments' in pr_activity.columns:
                    total_reviewer_comments = pr_activity['Total Reviewer Comments'].sum()
                if 'Total Approver Comments' in pr_activity.columns:
                    total_approver_comments = pr_activity['Total Approver Comments'].sum()
                if 'Total Resolved Conversations' in pr_activity.columns:
                    total_resolved = pr_activity['Total Resolved Conversations'].sum()
                if 'Total Unresolved Conversations' in pr_activity.columns:
                    total_unresolved = pr_activity['Total Unresolved Conversations'].sum()
                if 'Is Breaking Change' in pr_activity.columns:
                    total_breaking = pr_activity['Is Breaking Change'].value_counts().get('Yes', 0)
            
            with col1:
                st.metric(
                    label="Total Comments",
                    value=total_reviewer_comments + total_approver_comments
                )
            
            with col2:
                st.metric(
                    label="Reviewer Comments",
                    value=total_reviewer_comments
                )
            
            with col3:
                st.metric(
                    label="Approver Comments",
                    value=total_approver_comments
                )
            
            with col4:
                st.metric(
                    label="Breaking Change PRs",
                    value=total_breaking
                )
            
            # Conversation resolution metrics
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    label="Resolved Conversations",
                    value=total_resolved
                )
            
            with col2:
                st.metric(
                    label="Unresolved Conversations",
                    value=total_unresolved
                )
            
            # Display version type summary
            st.subheader("Version Types Summary")
            col1, col2, col3 = st.columns(3)
            
            # Helper function to safely get version counts
            def get_version_count(column_name):
                if column_name in pr_summary.columns:
                    if isinstance(pr_summary[column_name], (int, float)):
                        return pr_summary[column_name]
                    elif hasattr(pr_summary[column_name], 'sum'):
                        return pr_summary[column_name].sum()
                    else:
                        return 0
                return 0
            
            with col1:
                rc_versions = get_version_count('RC Versions')
                st.metric(label="RC Versions", value=rc_versions)
            
            with col2:
                npd_versions = get_version_count('NPD Versions')
                st.metric(label="NPD Versions", value=npd_versions)
            
            with col3:
                stable_versions = get_version_count('Stable Versions')
                st.metric(label="Stable Versions", value=stable_versions)
                
            # NEW SECTION: Contributor Branch and PR Metrics
            st.subheader("Contributor Branch and PR Metrics")
            
            # Calculate metrics from the data if available
            col1, col2, col3 = st.columns(3)
            
            # Placeholder values - these should be calculated from the actual data when available
            with col1:
                # Calculate total active branches if the data is available
                active_branches = 0
                if 'Active Branches' in contributor_summary.columns:
                    active_branches = contributor_summary['Active Branches'].sum()
                
                st.metric(
                    label="Active Branches", 
                    value=active_branches if active_branches > 0 else "N/A"
                )
            
            with col2:
                # Calculate total stale branches if the data is available
                stale_branches = 0
                if 'Stale Branches' in contributor_summary.columns:
                    stale_branches = contributor_summary['Stale Branches'].sum()
                
                st.metric(
                    label="Stale Branches", 
                    value=stale_branches if stale_branches > 0 else "N/A"
                )
            
            with col3:
                # We already have PR metrics, but we'll display it here for consistency
                total_prs = contributor_summary['Total PRs'].sum() if 'Total PRs' in contributor_summary.columns else 0
                
                st.metric(
                    label="Total PRs by Contributors", 
                    value=total_prs
                )
            
            # Add a detailed breakdown table showing contributor branch and PR metrics
            st.subheader("Contributor Branch and PR Activity Breakdown")
            
            # Create a dataframe for the breakdown if the branch metrics are available
            if any(col in contributor_summary.columns for col in ['Active Branches', 'Stale Branches']):
                branch_pr_metrics = contributor_summary[['Contributor']].copy()
                
                # Add branch metrics if available
                if 'Active Branches' in contributor_summary.columns:
                    branch_pr_metrics['Active Branches'] = contributor_summary['Active Branches']
                else:
                    branch_pr_metrics['Active Branches'] = "N/A"
                    
                if 'Stale Branches' in contributor_summary.columns:
                    branch_pr_metrics['Stale Branches'] = contributor_summary['Stale Branches']
                else:
                    branch_pr_metrics['Stale Branches'] = "N/A"
                
                # Add PR metrics from existing data
                branch_pr_metrics['Total PRs'] = contributor_summary['Total PRs']
                
                # Add repository information if available
                if 'Repository List' in contributor_summary.columns:
                    branch_pr_metrics['Repositories'] = contributor_summary['Repository List']
                
                # Sort by active branches (descending)
                if 'Active Branches' in contributor_summary.columns and not branch_pr_metrics['Active Branches'].equals(pd.Series(["N/A"] * len(branch_pr_metrics))):
                    branch_pr_metrics = branch_pr_metrics.sort_values(by='Active Branches', ascending=False)
                else:
                    # If Active Branches is not available, sort by Total PRs
                    branch_pr_metrics = branch_pr_metrics.sort_values(by='Total PRs', ascending=False)
                
                # Take top 10 contributors for display
                top_contributors = branch_pr_metrics.head(10)
                
                # Display the table
                st.dataframe(top_contributors, use_container_width=True)
            else:
                st.info("Branch metrics data not available in this report. To see branch metrics, you'll need to regenerate the report with branch tracking enabled.")
            
            # Repository health table
            st.subheader("Repository Health Overview")
            
            # Calculate health percentage for sorting
            health_overview = pr_summary[['Repository', 'Total PRs', 'Healthy PRs', 'Unhealthy PRs']].copy()
            # Rename for display
            health_overview = health_overview.rename(columns={'Unhealthy PRs': 'Needs Attention PRs'})
            
            # Ensure Health Percentage column exists, calculate if needed
            if 'Health Percentage' in pr_summary.columns:
                health_overview.loc[:, 'Health Percentage'] = pr_summary['Health Percentage'].values
            else:
                # Calculate health percentage safely
                health_overview.loc[:, 'Health Percentage'] = (
                    health_overview['Healthy PRs'] / health_overview['Total PRs'] * 100
                ).fillna(0).round(1)
            
            health_overview = health_overview.sort_values(by='Health Percentage', ascending=False)
            
            # Format the health percentage as a string with % sign for display
            health_overview.loc[:, 'Health Score'] = health_overview['Health Percentage'].apply(lambda x: f"{x}%")
            
            # Add a visual indicator of health (emoji only, no text)
            def health_indicator(percentage, total_prs):
                # Special case for repositories with no PRs
                if total_prs == 0:
                    return "âšª"  # White circle for Stable/No Dev repositories
                
                # Regular health indicators (emoji only, no text)
                if percentage >= 80:
                    return "ðŸŸ¢"  # Green circle
                elif percentage >= 50:
                    return "ðŸŸ¡"  # Yellow circle
                else:
                    return "ðŸ”´"  # Red circle
            
            # Apply the indicator with total PRs information
            health_overview.loc[:, 'Status'] = health_overview.apply(
                lambda row: health_indicator(row['Health Percentage'], row['Total PRs']), 
                axis=1
            )
            
            # Display the table
            st.dataframe(
                health_overview[['Repository', 'Total PRs', 'Healthy PRs', 'Needs Attention PRs', 'Health Score', 'Status']], 
                use_container_width=True
            )
            
        except Exception as e:
            st.error(f"Error creating overall summary: {str(e)}")
    
    def create_pr_summary(self, data):
        """Create PR activity summary view."""
        try:
            st.header("Pull Request Activity Summary")
            
            pr_summary = data['pr_summary']
            pr_activity = data['pr_activity']
            
            # High-level PR metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                avg_duration = pr_summary['Avg PR Duration (days)'].mean()
                st.metric(
                    label="Average PR Duration (days)", 
                    value=round(avg_duration, 1)
                )
            
            with col2:
                # Check if the columns exist before using them
                if all(col in pr_summary.columns for col in ['PRs With Comments', 'PRs Without Comments']):
                    prs_with_comments = pr_summary['PRs With Comments'].sum()
                    prs_without_comments = pr_summary['PRs Without Comments'].sum()
                    total_prs = prs_with_comments + prs_without_comments
                    
                    if total_prs > 0:
                        comment_percentage = round((prs_with_comments / total_prs) * 100, 1)
                    else:
                        comment_percentage = 0
                    
                    st.metric(
                        label="PRs With Comments", 
                        value=prs_with_comments,
                        delta=f"{comment_percentage}% of total"
                    )
                else:
                    st.metric(
                        label="PRs With Comments", 
                        value="N/A"
                    )
            
            with col3:
                if 'Breaking Change PRs' in pr_summary.columns:
                    breaking_prs = pr_summary['Breaking Change PRs'].sum()
                    st.metric(
                        label="Breaking Change PRs", 
                        value=breaking_prs
                    )
                else:
                    # Try to calculate from pr_activity
                    try:
                        if 'Is Breaking Change' in pr_activity.columns:
                            breaking_prs = pr_activity['Is Breaking Change'].value_counts().get('Yes', 0)
                            st.metric(
                                label="Breaking Change PRs", 
                                value=breaking_prs
                            )
                        else:
                            st.metric(
                                label="Breaking Change PRs", 
                                value="N/A"
                            )
                    except:
                        st.metric(
                            label="Breaking Change PRs", 
                            value="N/A"
                        )
            
            # Add Comment Metrics section
            st.subheader("PR Comment Metrics")
            if all(col in pr_activity.columns for col in ['Total Reviewer Comments', 'Total Approver Comments', 'Total Resolved Conversations', 'Total Unresolved Conversations']):
                # Group by repository and calculate aggregates
                comment_metrics = pr_activity.groupby('Repository').agg({
                    'Total Reviewer Comments': 'sum',
                    'Total Approver Comments': 'sum',
                    'Total Resolved Conversations': 'sum',
                    'Total Unresolved Conversations': 'sum'
                }).reset_index()
                
                # Calculate resolution ratio
                comment_metrics['Resolution Ratio (%)'] = (
                    comment_metrics['Total Resolved Conversations'] / 
                    (comment_metrics['Total Resolved Conversations'] + comment_metrics['Total Unresolved Conversations']) * 100
                ).round(1).fillna(0)
                
                # Sort by total comments
                comment_metrics = comment_metrics.sort_values(
                    by=['Total Reviewer Comments', 'Total Approver Comments'], 
                    ascending=False
                )
                
                # Display as a table
                st.dataframe(comment_metrics, use_container_width=True)
                
                # Add summary metrics
                col1, col2, col3 = st.columns(3)
                with col1:
                    total_reviewer = comment_metrics['Total Reviewer Comments'].sum()
                    total_approver = comment_metrics['Total Approver Comments'].sum()
                    total_comments = total_reviewer + total_approver
                    approver_percentage = round(total_approver / total_comments * 100, 1) if total_comments > 0 else 0
                    st.metric(
                        label="Total Comments", 
                        value=total_comments,
                        delta=f"{approver_percentage}% by approvers"
                    )
                
                with col2:
                    resolved = comment_metrics['Total Resolved Conversations'].sum()
                    unresolved = comment_metrics['Total Unresolved Conversations'].sum()
                    total_conversations = resolved + unresolved

                    # Fix the calculation by handling the case where there are no conversations
                    if total_conversations > 0:
                        resolution_rate = round(resolved / total_conversations * 100, 1)
                    else:
                        resolution_rate = 100.0  # If no conversations, consider 100% resolved
                                        
                    st.metric(
                        label="Resolution Rate", 
                        value=f"{resolution_rate}%"
                    )
                
                with col3:
                    total_prs = len(pr_activity)
                    avg_comments = round(total_comments / total_prs, 1) if total_prs > 0 else 0
                    st.metric(
                        label="Avg Comments per PR", 
                        value=avg_comments
                    )
            else:
                st.warning("Comment metrics not available in this report. Please regenerate with the latest version.")
            
            # Add Breaking Change section
            st.subheader("Breaking Change Analysis")
            if 'Is Breaking Change' in pr_activity.columns:
                breaking_changes = pr_activity[pr_activity['Is Breaking Change'] == 'Yes']
                breaking_count = len(breaking_changes)
                
                col1, col2 = st.columns(2)
                with col1:
                    total_prs = len(pr_activity)
                    breaking_percentage = round(breaking_count / total_prs * 100, 1) if total_prs > 0 else 0
                    st.metric(
                        label="Breaking Change PRs", 
                        value=breaking_count,
                        delta=f"{breaking_percentage}% of all PRs"
                    )
                
                with col2:
                    # Breaking changes by repository
                    breaking_by_repo = breaking_changes.groupby('Repository').size().reset_index(name='Count')
                    if not breaking_by_repo.empty:
                        top_breaking_repo = breaking_by_repo.sort_values('Count', ascending=False).iloc[0]['Repository']
                        top_count = breaking_by_repo.sort_values('Count', ascending=False).iloc[0]['Count']
                        st.metric(
                            label="Top Repository with Breaking Changes", 
                            value=top_breaking_repo,
                            delta=f"{top_count} breaking PRs"
                        )
                    else:
                        st.metric(
                            label="Top Repository with Breaking Changes", 
                            value="None"
                        )
                
                # Show breakdown by repository
                if not breaking_by_repo.empty:
                    breaking_by_repo = breaking_by_repo.sort_values(by='Count', ascending=False)
                    st.dataframe(breaking_by_repo, use_container_width=True)
                else:
                    st.info("No breaking changes found in this time period.")
            else:
                st.warning("Breaking change data not available in this report. Please regenerate with the latest version.")
            
            # Version Type Distribution
            if all(col in pr_summary.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Type Distribution")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    rc_versions = pr_summary['RC Versions'].sum()
                    st.metric(
                        label="RC Versions", 
                        value=rc_versions
                    )
                
                with col2:
                    npd_versions = pr_summary['NPD Versions'].sum()
                    st.metric(
                        label="NPD Versions", 
                        value=npd_versions
                    )
                
                with col3:
                    stable_versions = pr_summary['Stable Versions'].sum()
                    st.metric(
                        label="Stable Versions", 
                        value=stable_versions
                    )
                
            # PR Health by Repository
            st.subheader("PR Health by Repository")
            
            # Make sure the PR Health column exists and is properly formatted
            if 'PR Health' in pr_activity.columns:
                # Group PR activity data by repository and PR health
                # Extract the health status (Healthy/Needs Attention) by removing the emoji if present
                try:
                    health_by_repo = pd.crosstab(
                        pr_activity['Repository'], 
                        pr_activity['PR Health'].apply(lambda x: ' '.join(x.strip().split(' ')[1:]) if ' ' in x else x),
                        margins=False
                    )
                    
                    # Rename columns for better display
                    if 'Healthy' in health_by_repo.columns:
                        health_by_repo = health_by_repo.rename(columns={'Healthy': 'âœ… Healthy'})
                    if 'Needs Attention' in health_by_repo.columns:
                        health_by_repo = health_by_repo.rename(columns={'Needs Attention': 'âŒ Needs Attention'})
                    if 'Needs' in health_by_repo.columns:
                        health_by_repo = health_by_repo.rename(columns={'Needs': 'âŒ Needs Attention'})
                    
                    # Add total column
                    health_by_repo['Total PRs'] = health_by_repo.sum(axis=1)
                    
                    # Calculate health percentage
                    healthy_col = 'âœ… Healthy' if 'âœ… Healthy' in health_by_repo.columns else None
                    if healthy_col:
                        health_by_repo['Health %'] = (health_by_repo[healthy_col] / health_by_repo['Total PRs'] * 100).round(1)
                        health_by_repo['Health %'] = health_by_repo['Health %'].fillna(0)
                        
                        # Sort by health percentage
                        health_by_repo = health_by_repo.sort_values(by='Health %', ascending=False)
                    
                    # Display the table
                    st.dataframe(health_by_repo, use_container_width=True)
                except Exception as e:
                    st.error(f"Error processing PR health data: {str(e)}")
                    # Fallback to simpler grouping
                    repo_counts = pr_activity.groupby('Repository').size().reset_index(name='Total PRs')
                    st.dataframe(repo_counts, use_container_width=True)
            else:
                st.warning("PR Health data not available in the report.")
                repo_counts = pr_activity.groupby('Repository').size().reset_index(name='Total PRs')
                st.dataframe(repo_counts, use_container_width=True)
            
            # PR Checks Status by Repository
            if all(col in pr_activity.columns for col in ['Passed Checks', 'Failed Checks']):
                st.subheader("PR Checks Status by Repository")
                
                # Group PR activity data by repository and calculate check success metrics
                checks_by_repo = pr_activity.groupby('Repository').agg({
                    'Passed Checks': 'sum',
                    'Failed Checks': 'sum'
                }).reset_index()
                
                # Calculate total checks and success rate
                checks_by_repo['Total Checks'] = checks_by_repo['Passed Checks'] + checks_by_repo['Failed Checks']
                checks_by_repo['Success Rate (%)'] = (checks_by_repo['Passed Checks'] / checks_by_repo['Total Checks'] * 100).round(1)
                
                # Replace NaN with 0 for repositories with no checks
                checks_by_repo = checks_by_repo.fillna(0)
                
                # Sort by success rate
                checks_by_repo = checks_by_repo.sort_values(by='Success Rate (%)', ascending=False)
                
                # Display the table
                st.dataframe(checks_by_repo, use_container_width=True)
                
            # Version Types by Repository
            if all(col in pr_activity.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Types by Repository")
                
                # Group PR activity data by repository and calculate version type metrics
                versions_by_repo = pr_activity.groupby('Repository').agg({
                    'RC Versions': 'sum',
                    'NPD Versions': 'sum',
                    'Stable Versions': 'sum'
                }).reset_index()
                
                # Add total versions column
                versions_by_repo['Total Versions'] = versions_by_repo['RC Versions'] + versions_by_repo['NPD Versions'] + versions_by_repo['Stable Versions']
                
                # Calculate percentages
                for version_type in ['RC Versions', 'NPD Versions', 'Stable Versions']:
                    versions_by_repo[f'{version_type} (%)'] = (versions_by_repo[version_type] / versions_by_repo['Total Versions'] * 100).round(1)
                
                # Replace NaN with 0 for repositories with no versions
                versions_by_repo = versions_by_repo.fillna(0)
                
                # Sort by stable version percentage
                versions_by_repo = versions_by_repo.sort_values(by='Stable Versions (%)', ascending=False)
                
                # Display the table
                st.dataframe(versions_by_repo, use_container_width=True)
            
            # PR Age Distribution
            st.subheader("PR Age Distribution")
            
            # Make sure the Days Open column exists
            if 'Days Open' in pr_activity.columns:
                # Create bins for PR duration
                bins = [0, 1, 3, 7, 14, 30, float('inf')]
                labels = ['1 day or less', '1-3 days', '3-7 days', '7-14 days', '14-30 days', 'Over 30 days']
                
                pr_activity['Age Group'] = pd.cut(pr_activity['Days Open'], bins=bins, labels=labels)
                
                # Group by age
                age_distribution = pr_activity.groupby('Age Group').size().reset_index(name='Count')
                
                # Fill in missing groups with zero count
                all_groups = pd.DataFrame({'Age Group': labels})
                age_distribution = pd.merge(all_groups, age_distribution, on='Age Group', how='left').fillna(0)
                age_distribution['Count'] = age_distribution['Count'].astype(int)
                
                # Calculate percentage
                total_prs = age_distribution['Count'].sum()
                if total_prs > 0:
                    age_distribution.loc[:, 'Percentage'] = (age_distribution['Count'] / total_prs * 100).round(1)
                else:
                    age_distribution.loc[:, 'Percentage'] = 0
                
                # Display as a table
                st.dataframe(age_distribution, use_container_width=True)
            else:
                st.warning("PR age data not available in the report.")
            
            # Feature/Fix PR Metrics
            st.subheader("Feature/Fix PR Test and Examples Coverage")

            # Check if the new columns exist
            feat_fix_columns = ['Is Feature/Fix PR', 'Has Examples', 'Has Tests', 'Has Integration Tests']
            if all(col in pr_activity.columns for col in feat_fix_columns):
                # Filter to only include feature/fix PRs
                feat_fix_prs = pr_activity[pr_activity['Is Feature/Fix PR'] == 'Yes']
                
                if not feat_fix_prs.empty:
                    # Count metrics
                    total_feat_fix = len(feat_fix_prs)
                    with_examples = len(feat_fix_prs[feat_fix_prs['Has Examples'] == 'Yes'])
                    with_tests = len(feat_fix_prs[feat_fix_prs['Has Tests'] == 'Yes'])
                    with_integration = len(feat_fix_prs[feat_fix_prs['Has Integration Tests'] == 'Yes'])
                    
                    # Display metrics
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric(
                            label="Feature/Fix PRs", 
                            value=total_feat_fix
                        )
                    
                    with col2:
                        examples_percentage = round((with_examples / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Examples", 
                            value=with_examples,
                            delta=f"{examples_percentage}%"
                        )
                    
                    with col3:
                        tests_percentage = round((with_tests / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Tests", 
                            value=with_tests,
                            delta=f"{tests_percentage}%"
                        )
                    
                    with col4:
                        integration_percentage = round((with_integration / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Integration Tests", 
                            value=with_integration,
                            delta=f"{integration_percentage}%"
                        )
                    
                    # Show coverage by repository
                    st.subheader("Coverage by Repository")
                    
                    # Group by repository
                    coverage_by_repo = feat_fix_prs.groupby('Repository').agg({
                        'Is Feature/Fix PR': 'count',
                        'Has Examples': lambda x: (x == 'Yes').sum(),
                        'Has Tests': lambda x: (x == 'Yes').sum(),
                        'Has Integration Tests': lambda x: (x == 'Yes').sum()
                    }).reset_index()
                    
                    # Rename columns
                    coverage_by_repo = coverage_by_repo.rename(columns={
                        'Is Feature/Fix PR': 'Feature/Fix PRs',
                        'Has Examples': 'With Examples',
                        'Has Tests': 'With Tests',
                        'Has Integration Tests': 'With Integration Tests'
                    })
                    
                    # Calculate percentages
                    for col in ['With Examples', 'With Tests', 'With Integration Tests']:
                        coverage_by_repo[f'{col} (%)'] = (coverage_by_repo[col] / coverage_by_repo['Feature/Fix PRs'] * 100).round(1)
                    
                    # Sort by count
                    coverage_by_repo = coverage_by_repo.sort_values(by='Feature/Fix PRs', ascending=False)
                    
                    # Display table
                    st.dataframe(coverage_by_repo, use_container_width=True)
                else:
                    st.info("No Feature/Fix PRs found in this report.")
            else:
                st.warning("Feature/Fix PR metrics not available in this report. Please regenerate the report with the latest version.")
                
        except Exception as e:
            st.error(f"Error creating PR summary: {str(e)}")
    
    def create_contributor_summary(self, data):
        """Create contributor summary view with enhanced metrics."""
        try:
            st.header("Contributor Activity Summary")
            
            contributor_summary = data['contributor_summary']
            contributor_detail = data['contributor_detail']
            
            # High-level contributor metrics
            col1, col2, col3 = st.columns(3)
            
            with col1:
                total_contributors = len(contributor_summary)
                multi_repo_contributors = contributor_summary[contributor_summary['Repositories'] > 1].shape[0] if 'Repositories' in contributor_summary.columns else 0
                
                st.metric(
                    label="Total Contributors", 
                    value=total_contributors
                )
                
                if total_contributors > 0:
                    multi_repo_percentage = round((multi_repo_contributors / total_contributors) * 100, 1)
                    st.metric(
                        label="Multi-Repo Contributors", 
                        value=multi_repo_contributors,
                        delta=f"{multi_repo_percentage}% of total"
                    )
                else:
                    st.metric(
                        label="Multi-Repo Contributors", 
                        value=0,
                        delta="0% of total"
                    )
            
            with col2:
                total_commits = contributor_summary['Total Commits'].sum()
                avg_commits_per_contributor = round(total_commits / total_contributors, 1) if total_contributors > 0 else 0
                
                st.metric(
                    label="Total Commits", 
                    value=total_commits
                )
                
                st.metric(
                    label="Avg Commits per Contributor", 
                    value=avg_commits_per_contributor
                )
            
            with col3:
                total_prs = contributor_summary['Total PRs'].sum()
                avg_prs_per_contributor = round(total_prs / total_contributors, 1) if total_contributors > 0 else 0
                
                st.metric(
                    label="Total PRs", 
                    value=total_prs
                )
                
                st.metric(
                    label="Avg PRs per Contributor", 
                    value=avg_prs_per_contributor
                )
                
            # Add branch metrics section
            st.subheader("Branch Activity Metrics")

            branch_columns = ['Active Branches', 'Stale Branches']
            if any(col in contributor_summary.columns for col in branch_columns):
                # Create a dataframe for branch metrics
                branch_metrics = contributor_summary[['Contributor']].copy()
    
                # Add available branch metrics
                for col in branch_columns:
                    if col in contributor_summary.columns:
                        branch_metrics[col] = contributor_summary[col]
  
                # Add PR count for context
                branch_metrics['Total PRs'] = contributor_summary['Total PRs']
    
                # Calculate active-to-stale ratio if both metrics are available
                if all(col in contributor_summary.columns for col in branch_columns):
                    branch_metrics['Active:Stale Ratio'] = (
                        contributor_summary['Active Branches'] / 
                        contributor_summary['Stale Branches'].apply(lambda x: max(1, x))  # Avoid division by zero
                    ).round(2)
    
                # Filter to show only contributors with branch activity
                has_branch_activity = branch_metrics[branch_columns[0]] > 0
                if any(has_branch_activity):
                    active_contributors = branch_metrics[has_branch_activity]
        
                    # Sort by active branches
                    active_contributors = active_contributors.sort_values(
                        by=branch_columns[0],
                        ascending=False
                    )
        
                    # Display table
                    st.dataframe(active_contributors, use_container_width=True)
            
                    # Add summary metrics
                    col1, col2, col3 = st.columns(3)
        
                    with col1:
                        total_active = active_contributors[branch_columns[0]].sum()
                        st.metric(
                            label="Total Active Branches", 
                            value=total_active
                        )
        
                    with col2:
                        total_stale = active_contributors[branch_columns[1]].sum()
                        st.metric(
                            label="Total Stale Branches", 
                            value=total_stale
                        )
        
                    with col3:
                        total_branches = total_active + total_stale
                        if total_branches > 0:
                            health_ratio = round((total_active / total_branches) * 100, 1)
                        else:
                            health_ratio = 100.0  # If no branches, consider 100% active
                    
                        st.metric(
                            label="Branch Health", 
                            value=f"{health_ratio}% Active"
                        )
                else:
                    st.info("No branch activity found for any contributors.")
            else:
                st.warning("Branch metrics not available in this report. Please regenerate with branch tracking enabled.")
            
            # Add PR commit check metrics - NEW SECTION
            st.subheader("Contributor Check Metrics")
            col1, col2, col3 = st.columns(3)

            with col1:
                # Check if the new fields exist in the data
                if 'Total Commit Passed Checks' in contributor_summary.columns:
                    total_commit_passed = contributor_summary['Total Commit Passed Checks'].sum()
                    st.metric(
                        label="Total Commit Passed Checks", 
                        value=total_commit_passed
                    )
                else:
                    st.metric(
                        label="Total Commit Passed Checks", 
                        value="N/A"
                    )

            with col2:
                if 'Total Commit Failed Checks' in contributor_summary.columns:
                    total_commit_failed = contributor_summary['Total Commit Failed Checks'].sum()
                    st.metric(
                        label="Total Commit Failed Checks", 
                        value=total_commit_failed
                    )
                else:
                    st.metric(
                        label="Total Commit Failed Checks", 
                        value="N/A"
                    )

            with col3:
                if all(col in contributor_summary.columns for col in ['Total Commit Passed Checks', 'Total Commit Failed Checks']):
                    total_checks = total_commit_passed + total_commit_failed
                    success_rate = round((total_commit_passed / total_checks) * 100, 1) if total_checks > 0 else 0
                    st.metric(
                        label="Commit Check Success Rate", 
                        value=f"{success_rate}%"
                    )
                else:
                    st.metric(
                        label="Commit Check Success Rate", 
                        value="N/A"
                    )
                
            # Display average PR checks per contributor
            st.subheader("PR Checks by Contributor")
            
            # Check if columns exist
            pr_checks_columns = ['Contributor', 'Total PRs', 'Avg Passed Checks per PR', 'Avg Failed Checks per PR']
            if all(col in contributor_summary.columns for col in pr_checks_columns[1:]):
                # Create a DataFrame with only the check metrics
                pr_checks_df = contributor_summary[pr_checks_columns].copy()
                
                # Filter to only include contributors with PRs
                pr_checks_df = pr_checks_df[pr_checks_df['Total PRs'] > 0]
                
                # Sort by PRs descending
                pr_checks_df = pr_checks_df.sort_values(by='Total PRs', ascending=False)
                
                # Display as a table
                st.dataframe(pr_checks_df, use_container_width=True)
            else:
                st.warning("PR check metrics not available in this report. Please regenerate with the latest version.")
            
            # PR Comment Metrics (Moved from PR activity) - NEW SECTION
            st.subheader("PR Comment Metrics")
            comment_metrics_columns = [
                'Total Reviewer Comments', 'Total Approver Comments', 
                'Total Resolved Conversations', 'Total Unresolved Conversations'
            ]
            
            if all(col in contributor_summary.columns for col in comment_metrics_columns):
                # Create a dataframe for comment metrics by contributor
                comment_metrics = contributor_summary[['Contributor'] + comment_metrics_columns].copy()
                
                # Filter to only include contributors with comments
                has_comments = comment_metrics[comment_metrics_columns].sum(axis=1) > 0
                comment_metrics = comment_metrics[has_comments]
                
                # Add total comments column
                comment_metrics['Total Comments'] = comment_metrics['Total Reviewer Comments'] + comment_metrics['Total Approver Comments']
                
                # Sort by total comments
                comment_metrics = comment_metrics.sort_values(by='Total Comments', ascending=False)
                
                # Calculate resolution ratio
                comment_metrics['Resolution Rate (%)'] = (
                    comment_metrics['Total Resolved Conversations'] / 
                    (comment_metrics['Total Resolved Conversations'] + comment_metrics['Total Unresolved Conversations']) * 100
                ).round(1).fillna(0)
                
                # Display as a table
                if not comment_metrics.empty:
                    st.dataframe(comment_metrics, use_container_width=True)
                    
                    # Add summary metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        total_reviewer = comment_metrics['Total Reviewer Comments'].sum()
                        total_approver = comment_metrics['Total Approver Comments'].sum()
                        total_comments = total_reviewer + total_approver
                        approver_percentage = round(total_approver / total_comments * 100, 1) if total_comments > 0 else 0
                        st.metric(
                            label="Total Comments", 
                            value=total_comments,
                            delta=f"{approver_percentage}% by approvers"
                        )
                    
                    with col2:
                        resolved = comment_metrics['Total Resolved Conversations'].sum()
                        unresolved = comment_metrics['Total Unresolved Conversations'].sum()
                        total_conversations = resolved + unresolved
                        resolution_rate = round(resolved / total_conversations * 100, 1) if total_conversations > 0 else 0
                        st.metric(
                            label="Resolution Rate", 
                            value=f"{resolution_rate}%"
                        )
                    
                    with col3:
                        total_contributors_with_comments = len(comment_metrics)
                        avg_comments = round(total_comments / total_contributors_with_comments, 1) if total_contributors_with_comments > 0 else 0
                        st.metric(
                            label="Avg Comments per Contributor", 
                            value=avg_comments
                        )
                else:
                    st.info("No comment activity found for any contributors.")
            else:
                st.warning("Comment metrics not available in this report. Please regenerate with the latest version.")
                
            # Add Feature/Fix Coverage by Contributor (Moved from PR Activity) - NEW SECTION
            st.subheader("Feature/Fix Coverage by Contributor")
            coverage_columns = ['Contributor', 'Feature/Fix PRs', 'With Examples', 'With Tests', 'With Integration Tests',
                           'Examples Coverage (%)', 'Tests Coverage (%)', 'Integration Tests Coverage (%)']
            
            if all(col in contributor_summary.columns for col in coverage_columns[:5]):
                # Create a dataframe for coverage metrics by contributor
                coverage_df = contributor_summary[coverage_columns].copy()
                
                # Filter to only include contributors with feature/fix PRs
                coverage_df = coverage_df[coverage_df['Feature/Fix PRs'] > 0]
                
                # Sort by feature/fix PRs
                coverage_df = coverage_df.sort_values(by='Feature/Fix PRs', ascending=False)
                
                # Display as a table
                if not coverage_df.empty:
                    st.dataframe(coverage_df, use_container_width=True)
                    
                    # Add summary metrics
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        total_feat_fix = coverage_df['Feature/Fix PRs'].sum()
                        st.metric(
                            label="Feature/Fix PRs", 
                            value=total_feat_fix
                        )
                    
                    with col2:
                        with_examples = coverage_df['With Examples'].sum()
                        examples_percentage = round((with_examples / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Examples", 
                            value=with_examples,
                            delta=f"{examples_percentage}%"
                        )
                    
                    with col3:
                        with_tests = coverage_df['With Tests'].sum()
                        tests_percentage = round((with_tests / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Tests", 
                            value=with_tests,
                            delta=f"{tests_percentage}%"
                        )
                    
                    with col4:
                        with_integration = coverage_df['With Integration Tests'].sum()
                        integration_percentage = round((with_integration / total_feat_fix) * 100, 1) if total_feat_fix > 0 else 0
                        st.metric(
                            label="With Integration Tests", 
                            value=with_integration,
                            delta=f"{integration_percentage}%"
                        )
                else:
                    st.info("No feature/fix PRs found for any contributors.")
            else:
                st.warning("Feature/fix coverage metrics not available in this report. Please regenerate with the latest version.")
               
            # Add check status metrics (moved from PR activity)
            if all(col in contributor_summary.columns for col in ['Passed Checks', 'Failed Checks']):
                st.subheader("Check Status Metrics")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    passed_checks = contributor_summary['Passed Checks'].sum()
                    st.metric(
                        label="Total Passed Checks", 
                        value=passed_checks
                    )
                
                with col2:
                    failed_checks = contributor_summary['Failed Checks'].sum()
                    st.metric(
                        label="Total Failed Checks", 
                        value=failed_checks
                    )
                
                with col3:
                    success_rate = 0
                    if (passed_checks + failed_checks) > 0:
                        success_rate = round((passed_checks / (passed_checks + failed_checks)) * 100, 1)
                    
                    st.metric(
                        label="Check Success Rate", 
                        value=f"{success_rate}%"
                    )
                    
                # PR Checks Status by Contributor (Moved from PR Activity)
                st.subheader("PR Checks Status by Contributor")
                
                # Create a dataframe for check status by contributor
                checks_by_contributor = contributor_summary[['Contributor', 'Passed Checks', 'Failed Checks']].copy()
                
                # Calculate total checks and success rate
                checks_by_contributor['Total Checks'] = checks_by_contributor['Passed Checks'] + checks_by_contributor['Failed Checks']
                checks_by_contributor['Success Rate (%)'] = (checks_by_contributor['Passed Checks'] / checks_by_contributor['Total Checks'] * 100).round(1)
                
                # Replace NaN with 0 for contributors with no checks
                checks_by_contributor = checks_by_contributor.fillna(0)
                
                # Filter to only include contributors with checks
                checks_by_contributor = checks_by_contributor[checks_by_contributor['Total Checks'] > 0]
                
                # Sort by success rate
                checks_by_contributor = checks_by_contributor.sort_values(by='Success Rate (%)', ascending=False)
                
                # Display the table
                st.dataframe(checks_by_contributor, use_container_width=True)
            
            # Version Type Distribution
            if all(col in contributor_summary.columns for col in ['RC Versions', 'NPD Versions', 'Stable Versions']):
                st.subheader("Version Type Distribution")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    rc_versions = contributor_summary['RC Versions'].sum()
                    st.metric(
                        label="RC Versions", 
                        value=rc_versions
                    )
                
                with col2:
                    npd_versions = contributor_summary['NPD Versions'].sum()
                    st.metric(
                        label="NPD Versions", 
                        value=npd_versions
                    )
                
                with col3:
                    stable_versions = contributor_summary['Stable Versions'].sum()
                    st.metric(
                        label="Stable Versions", 
                        value=stable_versions
                    )
            
            # Top contributors by PR count
            st.subheader("Top 10 Contributors by PR Count")
            
            # Sort and get top 10
            top_contributors = contributor_summary.sort_values(by='Total PRs', ascending=False).head(10)
            
            # Ensure all required columns exist
            required_columns = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits', 'Health Percentage']
            for col in required_columns:
                if col not in top_contributors.columns:
                    if col == 'Health Percentage':
                        # Calculate it if not present
                        if 'Healthy PRs' in top_contributors.columns and 'Total PRs' in top_contributors.columns:
                            top_contributors['Health Percentage'] = (top_contributors['Healthy PRs'] / top_contributors['Total PRs'] * 100).round(1)
                            top_contributors['Health Percentage'] = top_contributors['Health Percentage'].fillna(0)
                        else:
                            top_contributors['Health Percentage'] = 0
                    else:
                        top_contributors[col] = 0
            
            # Add check status columns if they exist
            display_columns = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits', 'Health Score']
            
            # Create formatted health score
            if 'Health Percentage' in top_contributors.columns:
                top_contributors['Health Score'] = top_contributors['Health Percentage'].apply(lambda x: f"{x}%")
            else:
                # Include only existing columns
                display_columns = [col for col in display_columns if col != 'Health Score']
            
            # Add branch metrics columns if they exist
            if 'Active Branches' in top_contributors.columns:
                display_columns.insert(3, 'Active Branches')
            if 'Stale Branches' in top_contributors.columns:
                display_columns.insert(4, 'Stale Branches')
            
            # Add breaking change count if available
            if 'Breaking Change PRs' in top_contributors.columns:
                display_columns.append('Breaking Change PRs')
            
            # Add comment metrics if available
            for col in ['Total Reviewer Comments', 'Total Approver Comments']:
                if col in top_contributors.columns:
                    display_columns.append(col)
            
            # Add new commit check metrics if available
            for col in ['Total Commit Passed Checks', 'Total Commit Failed Checks', 'Avg Passed Checks per PR', 'Avg Failed Checks per PR']:
                if col in top_contributors.columns:
                    display_columns.append(col)
            
            # Add version and check data if available
            if all(col in top_contributors.columns for col in ['Passed Checks', 'Failed Checks']):
                def calculate_success_rate(row):
                    if (row['Passed Checks'] + row['Failed Checks']) > 0:
                        rate = round((row['Passed Checks'] / (row['Passed Checks'] + row['Failed Checks']) * 100), 1)
                        return f"{rate}%"
                    else:
                        return "N/A"
                        
                top_contributors['Check Success Rate'] = top_contributors.apply(calculate_success_rate, axis=1)
                display_columns.append('Check Success Rate')
            
            # Add version type counts if available
            for version_type in ['RC Versions', 'NPD Versions', 'Stable Versions']:
                if version_type in top_contributors.columns:
                    display_columns.append(version_type)
            
            # Make sure all display columns exist in the dataframe
            display_columns = [col for col in display_columns if col in top_contributors.columns]
            
            # Display the table
            if not display_columns:
                st.warning("No contributor data columns available for display")
            else:
                st.dataframe(
                    top_contributors[display_columns], 
                    use_container_width=True
                )
            
            # Contributor Health Summary
            st.subheader("Contributor Health Overview")
            
            # Add health status indicator
            if 'Health Percentage' in contributor_summary.columns:
                def health_status(percentage, total_prs=None):
                    # Special case for contributors with no PRs
                    if total_prs is not None and total_prs == 0:
                        return "âšª"  # White circle for no activity
                    
                    # Regular health indicators (emoji only, no text)
                    if percentage >= 80:
                        return "ðŸŸ¢"  # Green circle
                    elif percentage >= 50:
                        return "ðŸŸ¡"  # Yellow circle
                    else:
                        return "ðŸ”´"  # Red circle
                
                contributor_health = contributor_summary.copy()
                # Check if Total PRs column exists
                if 'Total PRs' in contributor_health.columns:
                    contributor_health['Health Status'] = contributor_health.apply(
                        lambda row: health_status(row['Health Percentage'], row['Total PRs']),
                        axis=1
                    )
                else:
                    contributor_health['Health Status'] = contributor_health['Health Percentage'].apply(
                        lambda x: health_status(x)
                    )
                
                # Group by health status
                health_counts = contributor_health.groupby('Health Status').size().reset_index(name='Count')
                
                # Display as a table
                st.dataframe(health_counts, use_container_width=True)
            else:
                st.warning("Health percentage data not available in the report.")
            
            # Complete Contributor Statistics with filtering
            st.subheader("Complete Contributor Statistics")

            # Create a copy of the contributor summary for display
            complete_stats = contributor_summary.copy()

            # Format health percentage as a string with % sign
            if 'Health Percentage' in complete_stats.columns:
                complete_stats['Health Score'] = complete_stats['Health Percentage'].apply(lambda x: f"{x}%")

            # Create a health status indicator
            if 'Health Percentage' in complete_stats.columns:
                def health_status_indicator(percentage, total_prs=None):
                    # Special case for contributors with no PRs
                    if total_prs is not None and total_prs == 0:
                        return "âšª"  # White circle for no activity
                    
                    # Regular health indicators (emoji only, no text)
                    if percentage >= 80:
                        return "ðŸŸ¢"  # Green circle
                    elif percentage >= 50:
                        return "ðŸŸ¡"  # Yellow circle
                    else:
                        return "ðŸ”´"  # Red circle
                
                if 'Total PRs' in complete_stats.columns:
                    complete_stats['Health Status'] = complete_stats.apply(
                        lambda row: health_status_indicator(row['Health Percentage'], row['Total PRs']),
                        axis=1
                    )
                else:
                    complete_stats['Health Status'] = complete_stats['Health Percentage'].apply(health_status_indicator)

            # Add check success rate if checks data is available
            if all(col in complete_stats.columns for col in ['Passed Checks', 'Failed Checks']):
                def calculate_success_rate(row):
                    if (row['Passed Checks'] + row['Failed Checks']) > 0:
                        rate = round((row['Passed Checks'] / (row['Passed Checks'] + row['Failed Checks']) * 100), 1)
                        return f"{rate}%"
                    else:
                        return "N/A"
                        
                complete_stats['Check Success Rate'] = complete_stats.apply(calculate_success_rate, axis=1)

            # Select columns for display
            display_cols = ['Contributor', 'Repositories', 'Total PRs', 'Total Commits']

            # Add branch metrics if available
            branch_cols = ['Active Branches', 'Stale Branches']
            display_cols.extend([col for col in branch_cols if col in complete_stats.columns])

            # Add health-related columns if available
            health_cols = ['Healthy PRs', 'Unhealthy PRs', 'Health Score', 'Health Status']
            display_cols.extend([col for col in health_cols if col in complete_stats.columns])

            # Add new commit check metrics if available
            for col in ['Total Commit Passed Checks', 'Total Commit Failed Checks', 'Avg Passed Checks per PR', 'Avg Failed Checks per PR']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Add breaking change column if available
            if 'Breaking Change PRs' in complete_stats.columns:
                display_cols.append('Breaking Change PRs')
            
            # Add comment metrics if available
            for col in ['Total Reviewer Comments', 'Total Approver Comments', 'Total Resolved Conversations', 'Total Unresolved Conversations']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Add feature/fix coverage metrics if available
            for col in ['Feature/Fix PRs', 'With Examples', 'With Tests', 'With Integration Tests',
                    'Examples Coverage (%)', 'Tests Coverage (%)', 'Integration Tests Coverage (%)']:
                if col in complete_stats.columns:
                    display_cols.append(col)

            # Rename Unhealthy PRs to Needs Attention PRs for display
            if 'Unhealthy PRs' in display_cols:
                complete_stats = complete_stats.rename(columns={'Unhealthy PRs': 'Needs Attention PRs'})
                # Update the display columns list
                display_cols = [col if col != 'Unhealthy PRs' else 'Needs Attention PRs' for col in display_cols]

            # Add version type columns if available
            version_cols = ['RC Versions', 'NPD Versions', 'Stable Versions']
            display_cols.extend([col for col in version_cols if col in complete_stats.columns])

            # Add check status columns if available
            check_cols = ['Passed Checks', 'Failed Checks', 'Check Success Rate']
            display_cols.extend([col for col in check_cols if col in complete_stats.columns])

            # Add filtering options
            st.write("Filter contributors:")
            col1, col2, col3 = st.columns(3)

            with col1:
                # Filter by contributor name
                search_term = st.text_input("Search by contributor name:", "", key="search_contributor")
                if search_term:
                    complete_stats = complete_stats[complete_stats['Contributor'].str.contains(search_term, case=False)]

            with col2:
                # Filter by minimum PRs
                min_prs = st.number_input("Minimum PRs:", min_value=0, value=0, key="min_prs")
                if min_prs > 0:
                    complete_stats = complete_stats[complete_stats['Total PRs'] >= min_prs]

            with col3:
                # Filter by health status
                if 'Health Status' in complete_stats.columns:
                    health_options = ["All"] + sorted(complete_stats['Health Status'].unique().tolist())
                    selected_health = st.selectbox("Health Status:", health_options, key="health_status")
                    if selected_health != "All":
                        complete_stats = complete_stats[complete_stats['Health Status'] == selected_health]

            # Add second row of filters
            col1, col2, col3 = st.columns(3)

            with col1:
                # Filter by repository count
                if 'Repositories' in complete_stats.columns:
                    min_repos = st.number_input("Minimum Repositories:", min_value=0, value=0, key="min_repos")
                    if min_repos > 0:
                        complete_stats = complete_stats[complete_stats['Repositories'] >= min_repos]

            with col2:
                # Filter by minimum commits
                min_commits = st.number_input("Minimum Commits:", min_value=0, value=0, key="min_commits")
                if min_commits > 0:
                    complete_stats = complete_stats[complete_stats['Total Commits'] >= min_commits]

            with col3:
                # Sort options
                sort_options = {
                    "Total PRs (high to low)": ("Total PRs", False),
                    "Total PRs (low to high)": ("Total PRs", True),
                    "Total Commits (high to low)": ("Total Commits", False),
                    "Total Commits (low to high)": ("Total Commits", True),
                    "Contributor (A-Z)": ("Contributor", True),
                    "Contributor (Z-A)": ("Contributor", False),
                }
                
                # Add sort options for branches if available
                if 'Active Branches' in complete_stats.columns:
                    sort_options["Active Branches (high to low)"] = ("Active Branches", False)
                    sort_options["Active Branches (low to high)"] = ("Active Branches", True)
                
                if 'Stale Branches' in complete_stats.columns:
                    sort_options["Stale Branches (high to low)"] = ("Stale Branches", False)
                
                # Add new sort options for commit checks
                if 'Total Commit Passed Checks' in complete_stats.columns:
                    sort_options["Commit Passed Checks (high to low)"] = ("Total Commit Passed Checks", False)
                
                if 'Avg Passed Checks per PR' in complete_stats.columns:
                    sort_options["Avg Passed Checks per PR (high to low)"] = ("Avg Passed Checks per PR", False)
                
                if 'Health Percentage' in complete_stats.columns:
                    sort_options["Health (high to low)"] = ("Health Percentage", False)
                    sort_options["Health (low to high)"] = ("Health Percentage", True)
                
                if 'Breaking Change PRs' in complete_stats.columns:
                    sort_options["Breaking Changes (high to low)"] = ("Breaking Change PRs", False)
                
                if 'Total Reviewer Comments' in complete_stats.columns:
                    sort_options["Comments (high to low)"] = ("Total Reviewer Comments", False)
                
                selected_sort = st.selectbox("Sort by:", list(sort_options.keys()), index=0, key="sort_option")
                sort_column, sort_ascending = sort_options[selected_sort]
                
                if sort_column in complete_stats.columns:
                    complete_stats = complete_stats.sort_values(by=sort_column, ascending=sort_ascending)

            # Make sure all display columns exist in the dataframe
            display_cols = [col for col in display_cols if col in complete_stats.columns]

            # Display the filtered and sorted table
            if complete_stats.empty:
                st.warning("No contributors match the selected filters.")
            else:
                st.write(f"Showing {len(complete_stats)} contributors")
                if not display_cols:
                    st.warning("No contributor data columns available for display")
                else:
                    st.dataframe(
                        complete_stats[display_cols],
                        use_container_width=True
                    )
            
        except Exception as e:
            st.error(f"Error creating contributor summary: {str(e)}")
    
    def run(self):
        """Run the dashboard application."""
        # Add sidebar for configuration
        with st.sidebar:
            st.header("GitHub Metrics Dashboard")
            st.markdown("---")
            
            # Add report directory selector
            st.subheader("Report Selection")
            report_dirs = self.scan_for_report_directories()
            
            if not report_dirs:
                st.warning("No report directories or files found.")
                custom_dir = st.text_input("Enter custom report directory or path:")
            else:
                # Create formatted options for selection
                report_options = self.create_report_options(report_dirs)
                
                if not report_options:
                    st.warning("No valid reports found in any directories.")
                    custom_dir = st.text_input("Enter custom report directory or path:")
                else:
                    # Get the default (latest) directory
                    default_dir = self.find_latest_report()
                    default_idx = next((i for i, (_, dir_name) in enumerate(report_options) if dir_name == default_dir), 0)
                    
                    # Create selection box
                    selected_report = st.selectbox(
                        "Select report:",
                        [name for name, _ in report_options],
                        index=min(default_idx, len(report_options) - 1) if report_options else 0
                    )
                    
                    # Get the corresponding directory
                    custom_dir = next((dir_name for name, dir_name in report_options if name == selected_report), None)
            
            # Always allow manual entry of a custom directory
            if st.checkbox("Specify custom directory", value=False):
                custom_input = st.text_input("Enter custom report directory or path:")
                if custom_input:
                    custom_dir = custom_input
            
            st.markdown("---")
            st.markdown("### About")
            st.markdown("This dashboard visualizes GitHub metrics generated by the GitHub Metrics Reporter.")
        
        # Load report data
        data, report_dir = self.load_report_data(custom_dir)
        
        if not data:
            st.error("No data available. Please select a valid report directory.")
            return
        
        # Create tabs for different views
        tab1, tab2, tab3 = st.tabs(["Overall Summary", "Contributor Summary", "PR Activity Summary"])
        
        with tab1:
            self.create_overall_summary(data)
            
        with tab2:
            # Extract date ranges from PR data for filtering
            pr_activity = data['pr_activity']
            
            # Extract min and max dates
            min_date = datetime.now()
            max_date = datetime(2000, 1, 1)
            
            if 'Created Date' in pr_activity.columns:
                # Parse dates if they're strings
                if isinstance(pr_activity['Created Date'].iloc[0], str):
                    pr_activity['Created Date'] = pd.to_datetime(pr_activity['Created Date'])
                
                date_col = 'Created Date'
                min_date = pr_activity[date_col].min()
                max_date = pr_activity[date_col].max()
                
                # Add weekly range filter to contributor tab
                st.markdown("## Date Range Filter")
                start_date, end_date = self.add_weekly_range_filter(min_date, max_date, section_key="contributor")
                
                # Filter contributor data based on PRs in the selected date range
                # Find PRs within date range
                filtered_prs = pr_activity[(pr_activity[date_col] >= pd.Timestamp(start_date)) & 
                                        (pr_activity[date_col] <= pd.Timestamp(end_date))]
                
                # Get unique contributors in filtered PRs
                filtered_contributors = filtered_prs['Author'].unique()
                
                # Filter contributor summary
                filtered_contributor_summary = data['contributor_summary'][
                    data['contributor_summary']['Contributor'].isin(filtered_contributors)
                ]
                
                # Create a copy of data with filtered contributors
                filtered_data = data.copy()
                filtered_data['contributor_summary'] = filtered_contributor_summary
                
                # Display filtered data
                self.create_contributor_summary(filtered_data)
            else:
                # If date column not available, show unfiltered data
                self.create_contributor_summary(data)
            
        with tab3:
            # Extract date ranges from PR data for filtering
            pr_activity = data['pr_activity']
            
            # Extract min and max dates
            if 'Created Date' in pr_activity.columns:
                # Parse dates if they're strings
                if isinstance(pr_activity['Created Date'].iloc[0], str):
                    pr_activity['Created Date'] = pd.to_datetime(pr_activity['Created Date'])
                
                date_col = 'Created Date'
                min_date = pr_activity[date_col].min()
                max_date = pr_activity[date_col].max()
                
                # Add weekly range filter to PR activity tab
                st.markdown("## Date Range Filter")
                start_date, end_date = self.add_weekly_range_filter(min_date, max_date, section_key="pr_activity")
                
                # Filter PR data
                filtered_prs = pr_activity[(pr_activity[date_col] >= pd.Timestamp(start_date)) & 
                                        (pr_activity[date_col] <= pd.Timestamp(end_date))]
                
                # Create a copy of data with filtered PRs
                filtered_data = data.copy()
                filtered_data['pr_activity'] = filtered_prs
                
                # Update or create aggregated repository summary from filtered PRs
                repo_summary = data['pr_summary'].copy()
                
                # Display filtered data
                self.create_pr_summary(filtered_data)
            else:
                # If date column not available, show unfiltered data
                self.create_pr_summary(data)

if __name__ == "__main__":
    dashboard = GitHubMetricsDashboard()
    dashboard.run()